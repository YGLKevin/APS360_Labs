{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab_4_Data_Imputation.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"OhtOdxzd1ppr"},"source":["# Lab 4: Data Imputation using an Autoencoder\n","\n","**Deadline**: Thursday, Oct 29, 11:59pm\n","\n","**Late Penalty**: There is a penalty-free grace period of one hour past the deadline. Any work that is submitted between 1 hour and 24 hours past the deadline will receive a 20% grade deduction. No other late work is accepted. Quercus submission time will be used, not your local computer time. You can submit your labs as many times as you want before the deadline, so please submit often and early.\n","\n","**TA**: Chris Lucasius\n","\n","In this lab, you will build and train an autoencoder to impute (or \"fill in\") missing data. \n","\n","We will be using the\n","Adult Data Set provided by the UCI Machine Learning Repository [1], available \n","at https://archive.ics.uci.edu/ml/datasets/adult.\n","The data set contains census record files of adults, including their\n","age, martial status, the type of work they do, and other features. \n","\n","Normally, people use this data set to build a supervised classification\n","model to classify whether a person is a high income earner.\n","We will not use the dataset for this original intended purpose.\n","\n","Instead, we will perform the task of imputing (or \"filling in\") missing values in the dataset. For example,\n","we may be missing one person's martial status, and another person's age, and\n","a third person's level of education. Our model will predict the missing features \n","based on the information that we do have about each person.\n","\n","We will use a variation of a denoising autoencoder to solve this data imputation\n","problem. Our autoencoder will be trained using inputs that have one categorical feature artificially\n","removed, and the goal of the autoencoder is to correctly reconstruct all features,\n","including the one removed from the input.\n","\n","In the process, you are expected to learn to:\n","\n","1. Clean and process continuous and categorical data for machine learning.\n","2. Implement an autoencoder that takes continuous and categorical (one-hot) inputs.\n","3. Tune the hyperparameters of an autoencoder.\n","4. Use baseline models to help interpret model performance.\n","\n","[1] Dua, D. and Karra Taniskidou, E. (2017). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n","\n","\n","### What to submit\n","\n","Submit a PDF file containing all your code, outputs, and write-up. You can produce a PDF of your Google Colab file by going to File > Print and then save as PDF. The Colab instructions have more information (.html files are also acceptable).\n","\n","Do not submit any other files produced by your code.\n","\n","Include a link to your colab file in your submission.\n"]},{"cell_type":"markdown","metadata":{"id":"zbnrp2ig1pps"},"source":["## Colab Link\n","\n","Include a link to your Colab file here. If you would like the TA to look at your\n","Colab file in case your solutions are cut off, **please make sure that your Colab\n","file is publicly accessible at the time of submission**.\n","\n","Colab Link: https://drive.google.com/file/d/1KIIl8MNYpuvk89FA9Nq-h-ltq_83xAkT/view?usp=sharing"]},{"cell_type":"code","metadata":{"id":"z3p8N43E1ppt"},"source":["import csv\n","import time\n","import numpy as np\n","import random\n","import torch\n","import torch.utils.data\n","import matplotlib.pyplot as plt\n","from torch.utils.data import DataLoader\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-pp9Y9IoeKc5","executionInfo":{"status":"ok","timestamp":1604550762212,"user_tz":300,"elapsed":197,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"c81981f2-84f0-405e-d5a3-cf70af6ab12d","colab":{"base_uri":"https://localhost:8080/"}},"source":["# link to your Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8ROwtHcz1ppx"},"source":["## Part 0\n","\n","We will be using a package called `pandas` for this assignment. \n","\n","If you are using Colab, `pandas` should already be available.\n","If you are using your own computer,\n","installation instructions for `pandas` are available here: \n","https://pandas.pydata.org/pandas-docs/stable/install.html"]},{"cell_type":"code","metadata":{"id":"IXQ7BP151ppz"},"source":["import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hqXihb4Q1pp2"},"source":["# Part 1. Data Cleaning [15 pt]\n","\n","The adult.data file is available at `https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data`\n","\n","The function `pd.read_csv` loads the adult.data file into a pandas dataframe.\n","You can read about the pandas documentation for `pd.read_csv` at\n","https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"]},{"cell_type":"code","metadata":{"id":"EOMItFKn1pp3"},"source":["header = ['age', 'work', 'fnlwgt', 'edu', 'yredu', 'marriage', 'occupation',\n"," 'relationship', 'race', 'sex', 'capgain', 'caploss', 'workhr', 'country']\n","df = pd.read_csv(\n","    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n","    names=header,\n","    index_col=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"62Ot405q1pp5","scrolled":true,"executionInfo":{"status":"ok","timestamp":1604547759076,"user_tz":300,"elapsed":1249,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"f6dfa061-3b0a-46aa-8a92-0ab1c311b4d9","colab":{"base_uri":"https://localhost:8080/"}},"source":["df.shape # there are 32561 rows (records) in the data frame, and 14 columns (features)\n","#df.info # Print a concise summary of a DataFrame."],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(32561, 14)"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"markdown","metadata":{"id":"Tr7YG-QY1pp8"},"source":["### Part (a) Continuous Features [3 pt]\n","\n","For each of the columns `[\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]`, report the minimum, maximum, and average value across the dataset. \n","\n","Then, normalize each of the features `[\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]`\n","so that their values are always between 0 and 1.\n","Make sure that you are actually modifying the dataframe `df`. \n","\n","Like numpy arrays and torch tensors, \n","pandas data frames can be sliced. For example, we can\n","display the first 3 rows of the data frame (3 records) below."]},{"cell_type":"code","metadata":{"id":"9evSLsSa1pp9","scrolled":false,"executionInfo":{"status":"ok","timestamp":1604547759076,"user_tz":300,"elapsed":1241,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"f6c70aa7-8153-4060-afb3-e669714c3b6e","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["df[:3] # show the first 3 records"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>work</th>\n","      <th>fnlwgt</th>\n","      <th>edu</th>\n","      <th>yredu</th>\n","      <th>marriage</th>\n","      <th>occupation</th>\n","      <th>relationship</th>\n","      <th>race</th>\n","      <th>sex</th>\n","      <th>capgain</th>\n","      <th>caploss</th>\n","      <th>workhr</th>\n","      <th>country</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>State-gov</td>\n","      <td>77516</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Never-married</td>\n","      <td>Adm-clerical</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>2174</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50</td>\n","      <td>Self-emp-not-inc</td>\n","      <td>83311</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>United-States</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>Private</td>\n","      <td>215646</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Divorced</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   age               work  fnlwgt  ... caploss  workhr         country\n","0   39          State-gov   77516  ...       0      40   United-States\n","1   50   Self-emp-not-inc   83311  ...       0      13   United-States\n","2   38            Private  215646  ...       0      40   United-States\n","\n","[3 rows x 14 columns]"]},"metadata":{"tags":[]},"execution_count":66}]},{"cell_type":"markdown","metadata":{"id":"gBOojI6W1pqA"},"source":["Alternatively, we can slice based on column names, \n","for example `df[\"race\"]`, `df[\"hr\"]`, or even index multiple columns \n","like below."]},{"cell_type":"code","metadata":{"id":"4v6pp73A1pqB","executionInfo":{"status":"ok","timestamp":1604547759077,"user_tz":300,"elapsed":1235,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"eb31aaf1-ebe5-4a3c-98f0-ac8e71e013aa","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["subdf = df[[\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]]\n","subdf[:3] # show the first 3 records"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>yredu</th>\n","      <th>capgain</th>\n","      <th>caploss</th>\n","      <th>workhr</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>13</td>\n","      <td>2174</td>\n","      <td>0</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   age  yredu  capgain  caploss  workhr\n","0   39     13     2174        0      40\n","1   50     13        0        0      13\n","2   38      9        0        0      40"]},"metadata":{"tags":[]},"execution_count":67}]},{"cell_type":"markdown","metadata":{"id":"2Nru2P0E1pqD"},"source":["Numpy works nicely with pandas, like below:"]},{"cell_type":"code","metadata":{"id":"JXrS6tjp1pqE","executionInfo":{"status":"ok","timestamp":1604547759077,"user_tz":300,"elapsed":1228,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"354edb65-8511-4a82-a97d-1abdb5f06006","colab":{"base_uri":"https://localhost:8080/"}},"source":["np.sum(subdf[\"caploss\"])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2842700"]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"markdown","metadata":{"id":"Mv5mbxDM1pqH"},"source":["Just like numpy arrays, you can modify\n","entire columns of data rather than one scalar element at a time.\n","For example, the code  \n","\n","`df[\"age\"] = df[\"age\"] + 1` \n","\n","would increment everyone's age by 1."]},{"cell_type":"code","metadata":{"id":"k5rlWD7-1pqH","executionInfo":{"status":"ok","timestamp":1604550757009,"user_tz":300,"elapsed":157,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"d4e27cd6-4114-4973-c0a2-1c902e58b04e","colab":{"base_uri":"https://localhost:8080/"}},"source":["# print minimum, maximum, and average value for [\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]\n","selected_features = [\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]\n","for feature in selected_features:\n","  print(\"Selected feature:\", feature)\n","  print(\"Max value=\", df[feature].max())\n","  print(\"Min value=\", df[feature].min())\n","  print(\"Average=\", round(df[feature].mean()))\n","  print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected feature: age\n","Max value= 1.0\n","Min value= 0.0\n","Average= 0\n","\n","Selected feature: yredu\n","Max value= 1.0\n","Min value= 0.0\n","Average= 1\n","\n","Selected feature: capgain\n","Max value= 1.0\n","Min value= 0.0\n","Average= 0\n","\n","Selected feature: caploss\n","Max value= 1.0\n","Min value= 0.0\n","Average= 0\n","\n","Selected feature: workhr\n","Max value= 1.0\n","Min value= 0.0\n","Average= 0\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vXx-wqHnFaO2","executionInfo":{"status":"ok","timestamp":1604550755390,"user_tz":300,"elapsed":439,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"a6f53405-e19f-4427-ea5c-c98b00a36709","colab":{"base_uri":"https://localhost:8080/"}},"source":["# normalizing [\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]\n","selected_features = [\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]\n","for feature in selected_features:\n","  x = df[feature]\n","  normalized_value = (x - x.min())/(x.max() - x.min())\n","  x.update(normalized_value)\n","\n","# print first 3 samples after nomalization\n","print(df[[\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["            age     yredu   capgain  caploss    workhr\n","0      0.301370  0.800000  0.021740      0.0  0.397959\n","1      0.452055  0.800000  0.000000      0.0  0.122449\n","2      0.287671  0.533333  0.000000      0.0  0.397959\n","3      0.493151  0.400000  0.000000      0.0  0.397959\n","4      0.150685  0.800000  0.000000      0.0  0.397959\n","...         ...       ...       ...      ...       ...\n","32556  0.136986  0.733333  0.000000      0.0  0.377551\n","32557  0.315068  0.533333  0.000000      0.0  0.397959\n","32558  0.561644  0.533333  0.000000      0.0  0.397959\n","32559  0.068493  0.533333  0.000000      0.0  0.193878\n","32560  0.479452  0.533333  0.150242      0.0  0.397959\n","\n","[32561 rows x 5 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qbfMly4R1pqK"},"source":["### Part (b) Categorical Features [1 pt]\n","\n","What percentage of people in our data set are male? Note that the data labels all have an unfortunate space in the beginning, e.g. \" Male\" instead of \"Male\".\n","\n","What percentage of people in our data set are female?"]},{"cell_type":"code","metadata":{"id":"DjAjcsB_1pqK","executionInfo":{"status":"ok","timestamp":1604547759079,"user_tz":300,"elapsed":1212,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"4aff1c23-a807-4af3-c16d-614d058bf36f","colab":{"base_uri":"https://localhost:8080/"}},"source":["# hint: you can do something like this in pandas\n","num_of_male = sum(df[\"sex\"] == \" Male\")\n","num_of_female = sum(df[\"sex\"] == \" Female\")\n","total_num_of_people = len(df)\n","print(\"percentage of Male=\", round(num_of_male/total_num_of_people*100, 2), \"%\")\n","print(\"percentage of Female=\", round(num_of_female/total_num_of_people*100, 2), \"%\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["percentage of Male= 66.92 %\n","percentage of Female= 33.08 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eGVw7pqL1pqN"},"source":["### Part (c) [2 pt]\n","\n","Before proceeding, we will modify our data frame in a couple more ways:\n","\n","1. We will restrict ourselves to using a subset of the features (to simplify our autoencoder)\n","2. We will remove any records (rows) already containing missing values, and store them in a second dataframe. We will only use records without missing values to train our autoencoder.\n","\n","Both of these steps are done for you, below.\n","\n","How many records contained missing features? What percentage of records were removed?"]},{"cell_type":"code","metadata":{"id":"z6ewPUdv1pqO"},"source":["contcols = [\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]\n","catcols = [\"work\", \"marriage\", \"occupation\", \"edu\", \"relationship\", \"sex\"]\n","features = contcols + catcols\n","df = df[features]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fjdVll5a1pqQ","executionInfo":{"status":"ok","timestamp":1604550743536,"user_tz":300,"elapsed":180,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"96588b76-f812-411a-a904-c2b778b6dc63","colab":{"base_uri":"https://localhost:8080/"}},"source":["missing = pd.concat([df[c] == \" ?\" for c in catcols], axis=1).any(axis=1)\n","df_with_missing = df[missing]\n","df_not_missing = df[~missing]\n","print(\"# 0f rows that contains missing features =\", len(df_with_missing))\n","print(\"percentage of rows were removed = \", round(len(df_with_missing)/len(df)*100, 2), \"%\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["# 0f rows that contains missing features = 1843\n","percentage of rows were removed =  5.66 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XuEpndTQ1pqU"},"source":["### Part (d) One-Hot Encoding [1 pt]\n","\n","What are all the possible values of the feature \"work\" in `df_not_missing`? You may find the Python function `set` useful."]},{"cell_type":"code","metadata":{"id":"iKFh4owE1pqV","executionInfo":{"status":"ok","timestamp":1604550742611,"user_tz":300,"elapsed":194,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"8bac2eb7-6285-46b4-f155-9342bd90b05a","colab":{"base_uri":"https://localhost:8080/"}},"source":["work_types = df_not_missing[\"work\"].unique()\n","print(df_not_missing[\"work\"].nunique(), \"possible values in the feature 'work':\")\n","for work in work_types:\n","  print(work)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["7 possible values in the feature 'work':\n"," State-gov\n"," Self-emp-not-inc\n"," Private\n"," Federal-gov\n"," Local-gov\n"," Self-emp-inc\n"," Without-pay\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"COv3HaKr1pqY"},"source":["We will be using a one-hot encoding to represent each of the categorical variables.\n","Our autoencoder will be trained using these one-hot encodings.\n","\n","We will use the pandas function `get_dummies` to produce one-hot encodings\n","for all of the categorical variables in `df_not_missing`. "]},{"cell_type":"code","metadata":{"id":"eKlSYmJg1pqZ"},"source":["data = pd.get_dummies(df_not_missing)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3y7nTZ7H1pqb","scrolled":true,"executionInfo":{"status":"ok","timestamp":1604550739377,"user_tz":300,"elapsed":233,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"0b30321c-9ee1-4126-c382-3d44743a4da6","colab":{"base_uri":"https://localhost:8080/","height":223}},"source":["data[:3]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>yredu</th>\n","      <th>capgain</th>\n","      <th>caploss</th>\n","      <th>workhr</th>\n","      <th>work_ Federal-gov</th>\n","      <th>work_ Local-gov</th>\n","      <th>work_ Private</th>\n","      <th>work_ Self-emp-inc</th>\n","      <th>work_ Self-emp-not-inc</th>\n","      <th>work_ State-gov</th>\n","      <th>work_ Without-pay</th>\n","      <th>marriage_ Divorced</th>\n","      <th>marriage_ Married-AF-spouse</th>\n","      <th>marriage_ Married-civ-spouse</th>\n","      <th>marriage_ Married-spouse-absent</th>\n","      <th>marriage_ Never-married</th>\n","      <th>marriage_ Separated</th>\n","      <th>marriage_ Widowed</th>\n","      <th>occupation_ Adm-clerical</th>\n","      <th>occupation_ Armed-Forces</th>\n","      <th>occupation_ Craft-repair</th>\n","      <th>occupation_ Exec-managerial</th>\n","      <th>occupation_ Farming-fishing</th>\n","      <th>occupation_ Handlers-cleaners</th>\n","      <th>occupation_ Machine-op-inspct</th>\n","      <th>occupation_ Other-service</th>\n","      <th>occupation_ Priv-house-serv</th>\n","      <th>occupation_ Prof-specialty</th>\n","      <th>occupation_ Protective-serv</th>\n","      <th>occupation_ Sales</th>\n","      <th>occupation_ Tech-support</th>\n","      <th>occupation_ Transport-moving</th>\n","      <th>edu_ 10th</th>\n","      <th>edu_ 11th</th>\n","      <th>edu_ 12th</th>\n","      <th>edu_ 1st-4th</th>\n","      <th>edu_ 5th-6th</th>\n","      <th>edu_ 7th-8th</th>\n","      <th>edu_ 9th</th>\n","      <th>edu_ Assoc-acdm</th>\n","      <th>edu_ Assoc-voc</th>\n","      <th>edu_ Bachelors</th>\n","      <th>edu_ Doctorate</th>\n","      <th>edu_ HS-grad</th>\n","      <th>edu_ Masters</th>\n","      <th>edu_ Preschool</th>\n","      <th>edu_ Prof-school</th>\n","      <th>edu_ Some-college</th>\n","      <th>relationship_ Husband</th>\n","      <th>relationship_ Not-in-family</th>\n","      <th>relationship_ Other-relative</th>\n","      <th>relationship_ Own-child</th>\n","      <th>relationship_ Unmarried</th>\n","      <th>relationship_ Wife</th>\n","      <th>sex_ Female</th>\n","      <th>sex_ Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.301370</td>\n","      <td>0.800000</td>\n","      <td>0.02174</td>\n","      <td>0.0</td>\n","      <td>0.397959</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.452055</td>\n","      <td>0.800000</td>\n","      <td>0.00000</td>\n","      <td>0.0</td>\n","      <td>0.122449</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.287671</td>\n","      <td>0.533333</td>\n","      <td>0.00000</td>\n","      <td>0.0</td>\n","      <td>0.397959</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        age     yredu  capgain  ...  relationship_ Wife  sex_ Female  sex_ Male\n","0  0.301370  0.800000  0.02174  ...                   0            0          1\n","1  0.452055  0.800000  0.00000  ...                   0            0          1\n","2  0.287671  0.533333  0.00000  ...                   0            0          1\n","\n","[3 rows x 57 columns]"]},"metadata":{"tags":[]},"execution_count":125}]},{"cell_type":"markdown","metadata":{"id":"HwjDg1uM1pqe"},"source":["### Part (e) One-Hot Encoding [2 pt]\n","\n","The dataframe `data` contains the cleaned and normalized data that we will use to train our denoising autoencoder.\n","\n","How many **columns** (features) are in the dataframe `data`?\n","\n","Briefly explain where that number come from."]},{"cell_type":"code","metadata":{"id":"yjZ5N0Tl1pqf","executionInfo":{"status":"ok","timestamp":1604550737594,"user_tz":300,"elapsed":169,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"667f694e-d8d5-41c9-f348-66afe229b996","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(\"columns=\", len(data.columns))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["columns= 57\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nkHg_pp3U_3r","executionInfo":{"status":"ok","timestamp":1604550735672,"user_tz":300,"elapsed":163,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"68f7ac80-7f63-46f1-9371-3004c2ad2a30","colab":{"base_uri":"https://localhost:8080/"}},"source":["# selected continuous and categorical features\n","catcols = [\"work\", \"marriage\", \"occupation\", \"edu\", \"relationship\", \"sex\"]\n","contcols = [\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]\n","\n","num_of_continuous_features = len(contcols)\n","num_of_categorical_variables = 0\n","for feature in catcols:\n","  # Count distinct values in each categorical features\n","  count = df_not_missing[feature].nunique()\n","  num_of_categorical_variables += count\n","\n","print(\"# of continuous features =\", num_of_continuous_features)\n","print(\"# of categorical variables =\", num_of_categorical_variables)\n","print(\"# of columns =\", num_of_continuous_features + num_of_categorical_variables)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["# of continuous features = 5\n","# of categorical variables = 52\n","# of columns = 57\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OEJ0Ci3l1pqh"},"source":["### Part (f) One-Hot Conversion [3 pt]\n","\n","We will convert the pandas data frame `data` into numpy, so that\n","it can be further converted into a PyTorch tensor.\n","However, in doing so, we lose the column label information that\n","a panda data frame automatically stores.\n","\n","Complete the function `get_categorical_value` that will return\n","the named value of a feature given a one-hot embedding.\n","You may find the global variables `cat_index` and `cat_values`\n","useful. (Display them and figure out what they are first.)\n","\n","We will need this function in the next part of the lab\n","to interpret our autoencoder outputs. So, the input\n","to our function `get_categorical_values` might not \n","actually be \"one-hot\" -- the input may instead \n","contain real-valued predictions from our neural network."]},{"cell_type":"code","metadata":{"id":"ZmovX6gu1pqi"},"source":["datanp = data.values.astype(np.float32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_GOnZRgmkRLS","executionInfo":{"status":"ok","timestamp":1604550732092,"user_tz":300,"elapsed":148,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"ee58c91a-1783-4aaf-f927-b8fd673761eb","colab":{"base_uri":"https://localhost:8080/"}},"source":["data.keys()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['age', 'yredu', 'capgain', 'caploss', 'workhr', 'work_ Federal-gov',\n","       'work_ Local-gov', 'work_ Private', 'work_ Self-emp-inc',\n","       'work_ Self-emp-not-inc', 'work_ State-gov', 'work_ Without-pay',\n","       'marriage_ Divorced', 'marriage_ Married-AF-spouse',\n","       'marriage_ Married-civ-spouse', 'marriage_ Married-spouse-absent',\n","       'marriage_ Never-married', 'marriage_ Separated', 'marriage_ Widowed',\n","       'occupation_ Adm-clerical', 'occupation_ Armed-Forces',\n","       'occupation_ Craft-repair', 'occupation_ Exec-managerial',\n","       'occupation_ Farming-fishing', 'occupation_ Handlers-cleaners',\n","       'occupation_ Machine-op-inspct', 'occupation_ Other-service',\n","       'occupation_ Priv-house-serv', 'occupation_ Prof-specialty',\n","       'occupation_ Protective-serv', 'occupation_ Sales',\n","       'occupation_ Tech-support', 'occupation_ Transport-moving', 'edu_ 10th',\n","       'edu_ 11th', 'edu_ 12th', 'edu_ 1st-4th', 'edu_ 5th-6th',\n","       'edu_ 7th-8th', 'edu_ 9th', 'edu_ Assoc-acdm', 'edu_ Assoc-voc',\n","       'edu_ Bachelors', 'edu_ Doctorate', 'edu_ HS-grad', 'edu_ Masters',\n","       'edu_ Preschool', 'edu_ Prof-school', 'edu_ Some-college',\n","       'relationship_ Husband', 'relationship_ Not-in-family',\n","       'relationship_ Other-relative', 'relationship_ Own-child',\n","       'relationship_ Unmarried', 'relationship_ Wife', 'sex_ Female',\n","       'sex_ Male'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":121}]},{"cell_type":"code","metadata":{"id":"YRIa5MBd1pql","executionInfo":{"status":"ok","timestamp":1604550729285,"user_tz":300,"elapsed":237,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"f3615365-8d55-42e8-a1ff-ce96a28adac7","colab":{"base_uri":"https://localhost:8080/"}},"source":["cat_index = {}  # Mapping of feature -> starting index of a categorical feature in data\n","cat_values = {} # Mapping of feature -> list of categorical values of each feature\n","\n","# build up the cat_index and cat_values dictionary\n","for i, header in enumerate(data.keys()):\n","    if \"_\" in header: # categorical header contains '_'\n","        feature, value = header.split() # E.g.: header = work_ Private, feature = work_, value = Private\n","        feature = feature[:-1] # remove the last char; it is always an underscore\n","        if feature not in cat_index:\n","            cat_index[feature] = i\n","            cat_values[feature] = [value]\n","        else:\n","            cat_values[feature].append(value)\n","\n","#print cat_index & cat_values\n","print(cat_index)\n","print(cat_values)\n","\n","# return the categorical values of a given feature in a given row. E.g.: output: values of 'work_ Federal-gov,\twork_ Local-gov,\twork_ Private,\twork_ Self-emp-inc,\twork_ Self-emp-not-inc,\twork_ State-gov, work_ Without-pay'\n","def get_onehot(record, feature): # records = rows\n","    \"\"\"\n","    Return the portion of `record` that is the one-hot encoding\n","    of `feature`. For example, since the feature \"work\" is stored\n","    in the indices from 5th to 12th in each record, calling `get_range(record, \"work\")`\n","    is equivalent to accessing `record[5:12]`.\n","    \n","    Args:\n","        - record: a numpy array representing one record, formatted\n","                  the same way as a row in `data.np`\n","        - feature: a string, should be an element of `catcols`\n","    \"\"\"\n","    start_index = cat_index[feature]\n","    stop_index = cat_index[feature] + len(cat_values[feature])\n","    return record[start_index:stop_index]\n","\n","def get_categorical_value(onehot, feature):\n","    \"\"\"\n","    Return the categorical value name of a feature given\n","    a one-hot vector representing the feature.\n","    \n","    Args:\n","        - onehot: a numpy array one-hot representation of the feature\n","        - feature: a string, should be an element of `catcols`\n","        \n","    Examples:\n","    \n","    >>> get_categorical_value(np.array([0., 0., 0., 0., 0., 1., 0.]), \"work\")\n","    'State-gov'\n","    >>> get_categorical_value(np.array([0.1, 0., 1.1, 0.2, 0., 1., 0.]), \"work\")\n","    'Private'\n","    \"\"\"\n","    max_value = np.amax(onehot)\n","    indices = np.where(onehot == max_value)\n","    # indices is a tuple\n","    return cat_values[feature][int(indices[0])]\n","\n","ret = get_categorical_value(np.array([0.1, 0., 1.1, 0.2, 0., 1., 0.]), \"work\")\n","print(ret)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'work': 5, 'marriage': 12, 'occupation': 19, 'edu': 33, 'relationship': 49, 'sex': 55}\n","{'work': ['Federal-gov', 'Local-gov', 'Private', 'Self-emp-inc', 'Self-emp-not-inc', 'State-gov', 'Without-pay'], 'marriage': ['Divorced', 'Married-AF-spouse', 'Married-civ-spouse', 'Married-spouse-absent', 'Never-married', 'Separated', 'Widowed'], 'occupation': ['Adm-clerical', 'Armed-Forces', 'Craft-repair', 'Exec-managerial', 'Farming-fishing', 'Handlers-cleaners', 'Machine-op-inspct', 'Other-service', 'Priv-house-serv', 'Prof-specialty', 'Protective-serv', 'Sales', 'Tech-support', 'Transport-moving'], 'edu': ['10th', '11th', '12th', '1st-4th', '5th-6th', '7th-8th', '9th', 'Assoc-acdm', 'Assoc-voc', 'Bachelors', 'Doctorate', 'HS-grad', 'Masters', 'Preschool', 'Prof-school', 'Some-college'], 'relationship': ['Husband', 'Not-in-family', 'Other-relative', 'Own-child', 'Unmarried', 'Wife'], 'sex': ['Female', 'Male']}\n","Private\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T_XXxZdh1pqv"},"source":["# more useful code, used during training, that depends on the function\n","# you write above\n","\n","def get_feature(record, feature):\n","    \"\"\"\n","    Return the categorical feature value of a record\n","    \"\"\"\n","    onehot = get_onehot(record, feature)\n","    return get_categorical_value(onehot, feature)\n","\n","def get_features(record):\n","    \"\"\"\n","    Return a dictionary of all categorical feature values of a record\n","    \"\"\"\n","    return { f: get_feature(record, f) for f in catcols }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1_5ZZR_J1pqy"},"source":["### Part (g) Train/Test Split [3 pt]\n","\n","Randomly split the data into approximately 70% training, 15% validation and 15% test.\n","\n","Report the number of items in your training, validation, and test set."]},{"cell_type":"code","metadata":{"id":"TE_fTJJf1pqz","executionInfo":{"status":"ok","timestamp":1604550723855,"user_tz":300,"elapsed":371,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"7d4b31ba-27f6-4dfc-a608-1af830d58e1e","colab":{"base_uri":"https://localhost:8080/"}},"source":["# set the numpy seed for reproducibility\n","# https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.seed.html\n","np.random.seed(50)\n","np.random.shuffle(datanp)\n","total_samples = len(data)\n","split1 = int(total_samples*0.7)\n","split2 = int(total_samples*0.85)\n","\n","train_data = datanp[:split1]\n","val_data = datanp[split1:split2]\n","test_data = datanp[split2:]\n","\n","print(\"# of training data=\", len(train_data))\n","print(\"# of validation data=\", len(val_data))\n","print(\"# of testing data=\", len(test_data))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["# of training data= 21502\n","# of validation data= 4608\n","# of testing data= 4608\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"h9wJAKOI1pq3"},"source":["## Part 2. Model Setup [5 pt]\n","\n","### Part (a) [4 pt]\n","\n","Design a fully-connected autoencoder by modifying the `encoder` and `decoder`\n","below.\n","\n","The input to this autoencoder will be the features of the `data`, with\n","one categorical feature recorded as \"missing\". The output of the autoencoder\n","should be the reconstruction of the same features, but with the missing\n","value filled in.\n","\n","**Note**: Do not reduce the dimensionality of the input too much!\n","The output of your embedding is expected to contain information \n","about ~11 features."]},{"cell_type":"code","metadata":{"id":"f3F--tdn1pq3"},"source":["from torch import nn\n","\n","class AutoEncoder(nn.Module):\n","    def __init__(self, hu1, hu2):\n","        self.hu1 = hu1\n","        self.hu2 = hu2\n","        self.name = \"AutoEncoder\"\n","        super(AutoEncoder, self).__init__()\n","        self.encoder = nn.Sequential(\n","            nn.Linear(57, self.hu1),\n","            nn.ReLU(),\n","            nn.Linear(self.hu1, self.hu2),\n","            nn.ReLU()\n","        )\n","        self.decoder = nn.Sequential(\n","            nn.Linear(self.hu2, self.hu1),\n","            nn.ReLU(),\n","            nn.Linear(self.hu1, 57),\n","            nn.Sigmoid() # get to the range (0, 1)\n","        )\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kuEzTSAv1pq6"},"source":["### Part (b) [1 pt]\n","\n","Explain why there is a sigmoid activation in the last step of the decoder.\n","\n","(**Note**: the values inside the data frame `data` and the training code in Part 3 might be helpful.)"]},{"cell_type":"markdown","metadata":{"id":"HYIVQjf66hXe"},"source":["Answer:\n","\n","\n","*   For continuous features, we have normalized them between 0 and. For categorical features, we have converted them into one-hot embeddings, which are also betowwen 0 and 1. Since all the values are between 0 and 1, we use the sigmoid to regulate the range of output between 0 and 1. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"jYwqFWVl1pq8"},"source":["## Part 3. Training [18] \n","\n","### Part (a) [6 pt]\n","\n","We will train our autoencoder in the following way:\n","\n","- In each iteration, we will hide one of the categorical features using the `zero_out_random_features` function\n","- We will pass the data with one missing feature through the autoencoder, and obtain a reconstruction\n","- We will check how close the reconstruction is compared to the original data -- including the value of the missing feature\n","\n","Complete the code to train the autoencoder, and plot the training and validation loss every few iterations.\n","You may also want to plot training and validation \"accuracy\" every few iterations, as we will define in\n","part (b). You may also want to checkpoint your model every few iterations or epochs.\n","\n","Use `nn.MSELoss()` as your loss function. (Side note: you might recognize that this loss function is not\n","ideal for this problem, but we will use it anyway.)"]},{"cell_type":"code","metadata":{"id":"IDQA_-dS1pq9"},"source":["def zero_out_feature(records, feature):\n","    \"\"\" Set the feature missing in records, by setting the appropriate\n","    columns of records to 0\n","    \"\"\"\n","    start_index = cat_index[feature]\n","    stop_index = cat_index[feature] + len(cat_values[feature])\n","    # there will be multiple rows(records), so we want to zero out all given records for given features\n","    records[:, start_index:stop_index] = 0 \n","    return records\n","\n","def zero_out_random_feature(records):\n","    \"\"\" Set one random feature missing in records, by setting the \n","    appropriate columns of records to 0\n","    \"\"\"\n","    return zero_out_feature(records, random.choice(catcols))\n","\n","def get_model_name(name, batch_size, learn_rate, epoch):\n","    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n","                                                   batch_size,\n","                                                   learn_rate,\n","                                                   epoch)\n","    return path\n","\n","def plotting(iterations, t_loss, v_loss, t_acc, v_acc):\n","    plt.title(\"Training/Validation Loss Curves\")\n","    plt.plot(iterations, t_loss, label=\"Training\")\n","    plt.plot(iterations, v_loss, label=\"Validation\")\n","    plt.xlabel(\"# of iterations\")\n","    plt.ylabel(\"Loss\")\n","    plt.legend(loc='best')\n","    plt.show()\n","\n","    plt.title(\"Training/Validation Accuracy Curves\")\n","    plt.plot(iterations, t_acc, label=\"Training\")\n","    plt.plot(iterations, v_acc, label=\"Validation\")\n","    plt.xlabel(\"# of iterations\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.legend(loc='best')\n","    plt.show()\n","\n","def train(model, train_loader, valid_loader, batch_size=64, num_epochs=5, learning_rate=1e-4, use_cuda=True):\n","    \"\"\" Training loop. You should update this.\"\"\"\n","    torch.manual_seed(42)\n","    criterion = nn.MSELoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    # Set up some numpy arrays to store the training/validation loss/accuracy\n","    train_acc = np.zeros(num_epochs)\n","    train_loss = np.zeros(num_epochs)\n","    val_acc = np.zeros(num_epochs)\n","    val_loss = np.zeros(num_epochs)\n","    intrations = np.zeros(num_epochs)\n","\n","    # training started\n","    print (\"Training Started...\")\n","    start_time = time.time()\n","\n","    for epoch in range(num_epochs):\n","        for data in train_loader:\n","\n","            #############################################\n","            #To Enable GPU Usage\n","            if use_cuda and torch.cuda.is_available():\n","              data = data.cuda()\n","              model = model.cuda()\n","            #############################################\n","\n","            datam = zero_out_random_feature(data.clone()) # zero out one categorical feature for all samples\n","            recon = model(datam)\n","            loss = criterion(recon, data)\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        # get accuracy and loss for this epoch on training data\n","        train_acc[epoch], train_loss[epoch] = get_accuracy(model, train_loader, criterion=criterion, use_cuda=use_cuda)\n","        # get accuracy and loss for this epoch on validation data\n","        val_acc[epoch], val_loss[epoch] = get_accuracy(model, valid_loader, criterion=criterion, use_cuda=use_cuda)\n","        #get number of iterations\n","        intrations[epoch] = (epoch)\n","\n","        # Save the current model (checkpoint) to a file\n","        model_path = get_model_name(model.name, batch_size, learning_rate, epoch)\n","        torch.save(model.state_dict(), model_path)\n","\n","        # displaying the epochs performance\n","        print((\"Epoch {}: Train acc: {}, Train loss: {} | Validation acc: {}, Validation loss: {}\").format(\n","            epoch + 1,\n","            round(train_acc[epoch]*100, 3),\n","            round(train_loss[epoch], 5),\n","            round(val_acc[epoch]*100, 3),\n","            round(val_loss[epoch], 5)))\n","\n","\n","    # show final training resilt summary\n","    print(\"===============Final training result summary===============\")\n","    print(\"Training accuracy: \", round(train_acc[-1]*100, 3))\n","    print(\"Training loss: \", round(train_loss[-1], 5))\n","    print(\"Validation accuracy: \", round(val_acc[-1]*100, 3))\n","    print(\"Validation loss: \", round(val_loss[-1], 5))\n","\n","    # print out the training time \n","    end_time = time.time()\n","    elapsed_time = end_time - start_time\n","    print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))\n","\n","    return intrations, train_loss, val_loss, train_acc, val_acc"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WKk01pwx1pq_"},"source":["### Part (b) [3 pt]\n","\n","While plotting training and validation loss is valuable, loss values are harder to compare\n","than accuracy percentages. It would be nice to have a measure of \"accuracy\" in this problem.\n","\n","Since we will only be imputing missing categorical values, we will define an accuracy measure.\n","For each record and for each categorical feature, we determine whether\n","the model can predict the categorical feature given all the other features of the record.\n","\n","A function `get_accuracy` is written for you. It is up to you to figure out how to\n","use the function. **You don't need to submit anything in this part.**\n","To earn the marks, correctly plot the training and validation accuracy every few \n","iterations as part of your training curve."]},{"cell_type":"code","metadata":{"id":"bHWLfCzM1pq_"},"source":["def get_accuracy(model, data_loader, criterion=nn.MSELoss(), use_cuda=False):\n","    total = 0\n","    total_loss = 0\n","    acc = 0\n","    count = 0\n","    for col in catcols:\n","        for item in data_loader: # minibatches\n","\n","            #############################################\n","            #To Enable GPU Usage\n","            if use_cuda and torch.cuda.is_available():\n","              item = item.cuda()\n","              model = model.cuda()\n","            #############################################\n","\n","            # convert cuba back to numpy array\n","            numpy_input = item.detach().cpu().numpy()\n","            # get output from model\n","            out = model(zero_out_feature(item.clone(), col))\n","            numpy_out = out.detach().cpu().numpy()\n","\n","            # calculate loss\n","            loss = criterion(out, item)\n","            total_loss += loss.item()\n","            count += 1\n","\n","            # calculate accuracy\n","            for i in range(numpy_out.shape[0]): # record in minibatch\n","                acc += int(get_feature(numpy_out[i], col) == get_feature(numpy_input[i], col))\n","                total += 1\n","    # return both accuracy and loss            \n","    return acc / total, float(total_loss) / (count)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SxCTlXoV1prB"},"source":["### Part (c) [4 pt]\n","\n","Run your updated training code, using reasonable initial hyperparameters.\n","\n","Include your training curve in your submission."]},{"cell_type":"code","metadata":{"id":"nj5b71l-1prC","executionInfo":{"status":"ok","timestamp":1604549325335,"user_tz":300,"elapsed":172734,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"b7d5f349-6ee8-4048-8fb0-b5c76daef055","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# get data loader for each dataset\n","batch_size=64\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=1)\n","valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, num_workers=1)\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=1)\n","\n","# Hyperparameters setting\n","learning_rate=1e-4\n","epochs=20\n","batch_size=64\n","\n","autoencoder = AutoEncoder(hu1=40, hu2=20)\n","intrations, train_loss, val_loss, train_acc, val_acc = train(autoencoder, train_loader, valid_loader, batch_size=batch_size, num_epochs=epochs, learning_rate=learning_rate)\n","# plot the training/validation accuracy/loss curves\n","plotting(intrations, train_loss, val_loss, train_acc, val_acc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training Started...\n","Epoch 1: Train acc: 41.092, Train loss: 0.12354 | Validation acc: 41.041, Validation loss: 0.12363\n","Epoch 2: Train acc: 45.941, Train loss: 0.07165 | Validation acc: 45.833, Validation loss: 0.07169\n","Epoch 3: Train acc: 46.07, Train loss: 0.0697 | Validation acc: 46.021, Validation loss: 0.06972\n","Epoch 4: Train acc: 47.982, Train loss: 0.06531 | Validation acc: 47.848, Validation loss: 0.06532\n","Epoch 5: Train acc: 52.99, Train loss: 0.05855 | Validation acc: 53.111, Validation loss: 0.05853\n","Epoch 6: Train acc: 53.511, Train loss: 0.05627 | Validation acc: 53.581, Validation loss: 0.05623\n","Epoch 7: Train acc: 54.217, Train loss: 0.05527 | Validation acc: 54.21, Validation loss: 0.05523\n","Epoch 8: Train acc: 54.843, Train loss: 0.05442 | Validation acc: 54.814, Validation loss: 0.05436\n","Epoch 9: Train acc: 55.413, Train loss: 0.05337 | Validation acc: 55.407, Validation loss: 0.05328\n","Epoch 10: Train acc: 56.253, Train loss: 0.05173 | Validation acc: 56.214, Validation loss: 0.05159\n","Epoch 11: Train acc: 56.567, Train loss: 0.04951 | Validation acc: 56.565, Validation loss: 0.04932\n","Epoch 12: Train acc: 56.833, Train loss: 0.04783 | Validation acc: 57.053, Validation loss: 0.04764\n","Epoch 13: Train acc: 57.126, Train loss: 0.0464 | Validation acc: 57.19, Validation loss: 0.04624\n","Epoch 14: Train acc: 57.436, Train loss: 0.04488 | Validation acc: 57.411, Validation loss: 0.04476\n","Epoch 15: Train acc: 57.926, Train loss: 0.04301 | Validation acc: 57.834, Validation loss: 0.04294\n","Epoch 16: Train acc: 58.383, Train loss: 0.04109 | Validation acc: 58.174, Validation loss: 0.04105\n","Epoch 17: Train acc: 59.328, Train loss: 0.03918 | Validation acc: 58.974, Validation loss: 0.03916\n","Epoch 18: Train acc: 59.926, Train loss: 0.03776 | Validation acc: 59.599, Validation loss: 0.03776\n","Epoch 19: Train acc: 60.501, Train loss: 0.03663 | Validation acc: 60.12, Validation loss: 0.03663\n","Epoch 20: Train acc: 60.439, Train loss: 0.03558 | Validation acc: 60.142, Validation loss: 0.03558\n","===============Final training result summary===============\n","Training accuracy:  60.439\n","Training loss:  0.03558\n","Validation accuracy:  60.142\n","Validation loss:  0.03558\n","Total time elapsed: 172.28 seconds\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXgV5dn48e+dPZCwJhAgYNgRZA+LogiisqjgLmgVauvS1rWt1fZXlbq8b2vtZmv1dd/FCoqoIApKURAkCYuENYQACQFCQhJIyH7//pgJHkJWyMnJcn+u61w5M/PMzD2Tc859nueZM4+oKsYYY0xt+fk6AGOMMU2LJQ5jjDF1YonDGGNMnVjiMMYYUyeWOIwxxtSJJQ5jjDF1YonDVElElojI7Pou21BEZIKIpHpMJ4rIhNqUPY19PS8iD5/u+sY0JZY4mhkROebxKBOR4x7TN9VlW6o6VVVfr++ytSEis0TkAxHJFpGLKln+NxGZX5dtquogVV1RD7HNEZFvKmz7TlV9/Ey3XcM+VURu8NY+GgMRuVFE4tzXa7r7heR8X8dlTmaJo5lR1bDyB7AXuMJj3tvl5UQkwHdR1splwAfAe8AtngtExB+YBdRbomoCZgNZVDgX3taQrxMR+SXwd+B/gM5AD+DfwIzT2FZjf303bapqj2b6AFKAi93nE4BU4EHgAPAm0B74BMgAjrjPoz3WXwH81H0+B/gGeNotuxuYepplewIrgaPAMuBZ4C2P5X7AQSACOM8t18pj+TTgEBAA/BjY6pZJBu7wKDcBSK3ifIQCr7nxbQEeqFD2IWCXu90twFXu/LOBAqAUOAZku/NfA57wWP82IAnnw34R0NVjmQJ3AjuBbPf4pZr/41lAGXANUAJEeSzzB37nEWs80N1dNgj4wo3hIPC7KmKt7Dw9CGwCCt3zXOn5qHC8Wz2Wj3DP6YIK5Z4B/lHJMbZ1z+d11ZyHusb9IDC/wjb+ATzjsc+XgXQgDXgC8HeX9QH+C+QAh4H3fP1+bkwPq3G0LFFAB5wPottxPqBfdad7AMeBf1Wz/hhgO84H+lPAyyIip1H2HeA7oCMwF7i5wrqjgWRVPayqq3He2Fd7LL8ZeEdVS3ASyOVAG5wk8jcRGVHNMZR7FOjtPibjfKP3tAu4AOfD5Q/AWyLSRVW34nzof6tOLa5dxQ27TWv/C1wPdAH2APMqFLscGAUMcctNribWW4A4VV2A8+Hs2eT4S5za1zScc3ArkC8i4ThJ+TOgK84H4fJq9lHRLJxaXzv3PFd6PtzjvQ7n/3iLG8N0IBN4C5giIu3ccgHATOCNSvZ3LhACfFiHGKuNG+ecT3PPRXlN9Xqc1x84iagE59wMBy4Ffuouexz4HOfLVTTwzzOMq1mxxNGylAGPqmqhqh5X1UxVXaCq+ap6FHgSuLCa9feo6ouqWorTTNQFp0mh1mVFpAfOB+Yjqlqkqt/gfCP3dBmw2GP6DdwmGhFpg9N08TqAqn6qqrvU8V+cN/sFtTgX1wNPqmqWqu7D+SZ8gqq+r6r7VbVMVd/DqR2MrsV2wflgf0VVE1S1EPgtcK6IxHiU+aOqZqvqXuArYFg127uFHz7s3uHk5qqfAr9X1e3uOdioqpk4iemAqv5FVQtU9aiqrq1l/OB8K9+nqsehxvPxU+ApVV3nxpCkqntUNR2nZnmdW24KcFhV4yvZX0d3WUkdYqw2blXdAyQAV7nLLgLyVXWNiHTGSbb3qWqeqh4C/oaT2ACKcb5QdXXP3zeYEyxxtCwZqlpQPiEirUTk/0Rkj4jk4rzJ27nfzCpzoPyJqua7T8PqWLYrkOUxD2BfhXWncXLieBOYKCJdgWuBXaq63j2GqSKyRkSyRCTbXTeiipg8da2w3z2eC0XkFhHZ4HbOZwPn1HK75ds+sT1VPYbzDbybR5kDHs/zqeI8isg4nKa98hrLO8BgESlPNN1xagMVVTW/tk76n9RwPqrb1+vAj9znP8L5X1YmE4ioh76Jiq+ld3BqIQA38kMCPgsIBNI9jun/gE7u8t8AAnznXo136xnG1axY4mhZKt4K+VdAf2CMqrYBxrvzq2p+qg/pQAcRaeUxr3v5ExGJwqmdJJTPc785fo3zwXMzbm1DRIKBBTh9KZ3dZqPFtYw/3XO/OE115TGcBbwI3AV0dLe72WO7Nd1Sej/OB1P59lrjfKNOq0VcFc1297tBRA4Aaz3mg/NB2buS9fYBvarYZh7gef6jKilz4hhrcT6qigFgITBERM7BqQW9XUW5b3H6Ja6sYnmd43a9D0wQkWicmkd54tjn7i9CVdu5jzaqOghAVQ+o6m2q2hW4A/i3iPSpJrYWxRJHyxaO06+RLSIdcNr9vcpNAnHAXBEJEpFzgSs8ikwFPlPVih8Ar+N8cI3jhw+fICAYp3O/RESm4rRT18Z/gN+KSHv3Q+Vuj2WtcT6AMgBE5Mc437DLHQSiRSSoim2/C/xYRIa5ye1/gLWqmlLL2HD3G4LTpHY7TlNW+eNu4Eb32/lLwOMi0lccQ0SkI86FDl1E5D4RCRaRcBEZ4256A07bfwc3Ud9XQyg1nY+XgF+LyEg3hj5ussGt4c7H7ddym+ZOoao5wCPAsyJypVsbDnRrlE+dZtyoagbOhRuvArvdPircZrTPgb+ISBsR8ROR3iJyoXuM17mvC3AuoFCcpl6DJY6W7u84VxcdBtbgdKQ2hJtwOkMzca5keQ/n2x+c2r9RbgFOx/5y902P2y9zD04SOILTFFGxv6Qqf8BpTtqN8wFyoglFVbcAf8H5FnwQGAys8lj3SyAROCAihytuWFWXAQ+7MafjfBufWbFcLVyJk9jfcL8BH1DVA8ArOFc6TQH+inP8nwO5OFcJhbrn5hKcpHwAp09iorvdN4GNOFchfY5z/qtU0/lQ1fdx+sfewbmqaiHO/6rc6+46VTVTlW/nLzid/b/HSVL7cL4sLDyduD28A1zMD7WNcrfgfPnYgvP6mY9T2wWnH26tiBzDeU3dq6rJtdxfsyenfrEzpmGJyHvANpwrWQ4AvVQ117dRmfriXhCxDecyYvu/NgNW4zANTkRGuc0CfiIyBecqqfJvqQ/bh0vzISJ+OLWIefZ/bT7s15XGF6JwfhXeEedHiT8rv0oKeM5nUZl65V4UcBCnSXCKj8Mx9ciaqowxxtSJNVUZY4ypkxbRVBUREaExMTG+DsMYY5qU+Pj4w6oaWXF+i0gcMTExxMXF+ToMY4xpUkRkT2XzranKGGNMnVjiMMYYUyeWOIwxxtRJi+jjqExxcTGpqakUFBTUXNjUKCQkhOjoaAIDA30dijHGy1ps4khNTSU8PJyYmBiqHovI1IaqkpmZSWpqKj179vR1OMYYL2uxTVUFBQV07NjRkkY9EBE6duxotTdjWogWmzgASxr1yM6lMS1Hi22qMsaYxkpVidtzhDW7Mgnw9yM00I/QIH9CAv0JDfQnNMj5G+I+yqdDA/0JDvDDz8+7X+QscfhIZmYmkyZNAuDAgQP4+/sTGen8QPO7774jKKiqMYIgLi6ON954g2eeeabKMgDnnXceq1evrr+gjTFetftwHh8mpPLhhjT2ZR0/7e2EBPqdSCRv3zaWnhGt6zFKSxw+07FjRzZs2ADA3LlzCQsL49e//vWJ5SUlJQQEVP7viY2NJTY2tsZ9WNIwpvE7klfEJ5v288H6NNbvzUYExvWO4P6L+3HpoCgC/ITjRaUcL3YfRaUUeDw/XuxOF5VyvLiM48WlFHosbx3sX+8xezVxuGMt/APwB15S1T9WUuZ6YC7O0IwbVfVGd/5snJHAAJ5Q1fJxpkcCr+GMXLcYZ2SuZnGL3zlz5hASEsL69esZN24cM2fO5N5776WgoIDQ0FBeffVV+vfvz4oVK3j66af55JNPmDt3Lnv37iU5OZm9e/dy3333cc899wAQFhbGsWPHWLFiBXPnziUiIoLNmzczcuRI3nrrLUSExYsX88tf/pLWrVszbtw4kpOT+eSTT3x8Joxp3gpLSvlq2yEWJKSxYvshikuV/p3D+e3UAcwY1o2otiEnlQ8J9Ke9j2KtjNcSh4j4A8/iDF+ZCqwTkUXuMJTlZfoCvwXGqeoREenkzi8f/zoWJ6HEu+sewRmv4TZgLU7imAIsOZNY//BxIlv21+8YMwO7tuHRKwbVeb3U1FRWr16Nv78/ubm5fP311wQEBLBs2TJ+97vfsWDBglPW2bZtG1999RVHjx6lf//+/OxnPzvl9xTr168nMTGRrl27Mm7cOFatWkVsbCx33HEHK1eupGfPnsyaNeu0j9cYUz1VJX7PET5Yn8anm9LJOV5MZHgws8+N4aoR3RjYpc0PF5nkZcK2T2DPaigthLJS56GlUFbiTpeAllWYLv2hbPn0zQuhQ/1eJu/NGsdoIKl8nF4RmYcz0tsWjzK3Ac+6CQFVPeTOnwx8oapZ7rpfAFNEZAXQRlXXuPPfwBmX+YwSR2Ny3XXX4e/vVC1zcnKYPXs2O3fuREQoLi6udJ3LLruM4OBggoOD6dSpEwcPHiQ6OvqkMqNHjz4xb9iwYaSkpBAWFkavXr1O/PZi1qxZvPDCC148OmNanpTDeXy4Po0P16exNyufkEA/pgyK4qoR0Yzr3ZEAf/fi1rzDsPVj2LIQdn/tfOiHRUFIGxB/8AsAPz/n74lpfwgMPXla/H547hcAAcH1fkzeTBzdcAabL5cKjKlQph+AiKzCac6aq6qfVbFuN/eRWsn8U4jI7cDtAD169Kg20NOpGXhL69Y/dGI9/PDDTJw4kQ8//JCUlBQmTJhQ6TrBwT+8MPz9/SkpKTmtMsaY+pFbUMwnG9OZH7+PBLff4rzeHblnUl+mnBNFWLD70XvsEGxdBFs+gpRvnBpEh95w/n0w8EqIGgyN8FJ3X3eOBwB9gQlANLBSRAbXx4ZV9QXgBYDY2Ngm2QeSk5NDt25OXnzttdfqffv9+/cnOTmZlJQUYmJieO+99+p9H8a0FGVlyrfJmbwft4/PEg9QUFxG305hPDhlAFcO70qXtqFOwaMHYOPHTrLYs8pJFh37wgW/cpJF50GNMll48mbiSAO6e0xHu/M8pQJrVbUY2C0iO3ASSRpOMvFcd4U7P7rC/IrbbDZ+85vfMHv2bJ544gkuu+yyet9+aGgo//73v5kyZQqtW7dm1KhR9b4PY5q7fVn5zI9PZX58KmnZxwkPCeCaEdFcH9udIdFtnX6L3P2w9g1IXAh7vwUUIgfA+N/AwBnQ6exGnyw8eW3McREJAHYAk3A+3NcBN6pqokeZKcAsVZ0tIhHAemAYboc4MMItmgCMVNUsEfkOuIcfOsf/qaqLq4slNjZWKw7ktHXrVs4+++wzP9Am7tixY4SFhaGq/OIXv6Bv377cf//9p7UtO6empTheVMqSzem8H5fKt8mZiMD5fSK4dmQ0kwdFERLoD8cy4Pv3nZrFvjXOip0GOrWKgTOg0wDfHkQtiEi8qp5y7b/XahyqWiIidwFLcfovXlHVRBF5DIhT1UXusktFZAtQCjygqpluwI/jJBuAx8o7yoGf88PluEtoRh3jvvDiiy/y+uuvU1RUxPDhw7njjjt8HZIxjZKqkrA3m/fj9vHJpnSOFZbQo0MrfnVJP64eGU23dqFQVga7V0D8a7DtU+fKps7nwMTfO8kisp+vD6NeeK3G0ZhYjaNh2Dk1zdHB3AI+SEjj/fh9JGfkERroz7TBXbguNprRMR2c23scPQDr34KENyB7D4R2gGE3wohbILK/rw/htDV4jcMYY5qyhL1H+NeXSazYfogyhdiz2nPHNb24bEhX56qoslJI+gISXoftS5zLZ3uOh0mPwNlXeOUy2MbCEocxxnjIPFbInz7bxn/iUokIC+bOC3tz7choekWGOQVyUuHbtyDhTchNhdaRcN5dMGI2dOzt2+AbiCUOY4wBSsuUd9bu4c9Lt5NfVMod43tx96S+Tu2itAS2LXZqFzs/dy6h7X0RTH4S+k+DgKpvStocWeIwxrR48XuO8MhHm0ncn8t5vTvyh+mD6Ns5HI7sgVVvOv0XR9MhrDOcfz8Mv7neb+PRlLTogZx8aeLEiSxduvSkeX//+9/52c9+Vmn5CRMmUN7BP23aNLKzs08pM3fuXJ5++ulq97tw4UK2bPnhri+PPPIIy5Ytq2v4xjQLh48V8sD7G7nmudVkHivin7OG8/ZPx9DXbz+8/2P4x1BY+bTzC+4b3ob7E50+jBacNMBqHD4za9Ys5s2bx+TJk0/MmzdvHk899VSN6y5eXO3PVqq1cOFCLr/8cgYOHAjAY489dtrbMqapKi1T3l67h6fLm6Uu7MU9F/Wl9dHd8MFt8P18CGrt3Poj9ifQrnvNG21BrMbhI9deey2ffvopRUVFAKSkpLB//37effddYmNjGTRoEI8++mil68bExHD48GEAnnzySfr168f555/P9u3bT5R58cUXGTVqFEOHDuWaa64hPz+f1atXs2jRIh544AGGDRvGrl27mDNnDvPnzwdg+fLlDB8+nMGDB3PrrbdSWFh4Yn+PPvooI0aMYPDgwWzbts2bp8YYr4rfk8UV//yGRz5KZHB0Wz677wJ+OzqI1ovvgmdHO7+/GHcv3LsJLp5rSaMSVuMAWPIQHPi+frcZNRimnjL8yAkdOnRg9OjRLFmyhBkzZjBv3jyuv/56fve739GhQwdKS0uZNGkSmzZtYsiQIZVuIz4+nnnz5rFhwwZKSkoYMWIEI0eOBODqq6/mtttuA+D3v/89L7/8MnfffTfTp0/n8ssv59prrz1pWwUFBcyZM4fly5fTr18/brnlFp577jnuu+8+ACIiIkhISODf//43Tz/9NC+99FJ9nCVjGszhY4X8cck25sen0qVtCM/eOIJp0QXIyodg47vgHwRjfw7j7oOwSF+H26hZjcOHypurwGmmmjVrFv/5z38YMWIEw4cPJzEx8aT+iIq+/vprrrrqKlq1akWbNm2YPn36iWWbN2/mggsuYPDgwbz99tskJiZWuR2A7du307NnT/r1c37ZOnv2bFauXHli+dVXXw3AyJEjSUlJOd1DNqbBlZSW8dqq3Ux8egUfbUjjzgt7s/wnvbgs5X+Rf8U6twUZcwfcu9G5SsqSRo2sxgHV1gy8acaMGdx///0kJCSQn59Phw4dePrpp1m3bh3t27dnzpw5FBQUnNa258yZw8KFCxk6dCivvfYaK1asOKNYy2/LbrdkN01JXEoWD3+UyNb0XM7vE8ETE9sRs/V5eP5N56aCsT9xrpJq08XXoTYpVuPwobCwMCZOnMitt97KrFmzyM3NpXXr1rRt25aDBw+yZEn1t+EaP348Cxcu5Pjx4xw9epSPP/74xLKjR4/SpUsXiouLefvtt0/MDw8P5+jRo6dsq3///qSkpJCUlATAm2++yYUXXlhPR2pMwygrUzbuy+bvy3Yw49lVXPv8t2TnF/Hy1d14s8v7xLxzvvPDvRG3wD0bYNpTljROg9U4fGzWrFlcddVVzJs3jwEDBjB8+HAGDBhA9+7dGTduXLXrjhgxghtuuIGhQ4fSqVOnk26L/vjjjzNmzBgiIyMZM2bMiWQxc+ZMbrvtNp555pkTneIAISEhvPrqq1x33XWUlJQwatQo7rzzTu8ctDH1KCe/mK+TMvhy2yH+uz2DzLwiRGBY93bMnRjBTSULCFz6mnNLkOE/csa9aFf94G6menaTQ1Nv7JyahqCqbD94lC+3HWLFtgzi9x6htExp1yqQqb2DuKJjOsP9dhF6aD2krILSIhg2C8Y/AO1jfB1+k2I3OTTGNFl5hSWsSjrMV9szWLH9EOk5BQRSwmWdDnNHv/0M80+iw5HvkZ27YCeAOGNfDP8RjP1Zi7mHVEOxxGGMaZT2ZOaxbOshVmw/xNrkTDqVHeTcoN080S6VoaFJdDy6DckthFwgLAqiY51EER0LXYdDcLivD6HZatGJQ1WdYR3NGWsJTZ7Gu1SV79Ny+DzxIF8mphGasYGxflv5eWgKz4fupHXJEadgXih0HQZn3+YkiehR0KZbkxp6talrsYkjJCSEzMxMOnbsaMnjDKkqmZmZhISE+DoU08QUlZSxJjmTLxIPsHNLAv3z47nA/3t+7r+NVsH5TqF2/aDbVIge6SSJTgPBP9C3gbdwXk0c7pji/8AZOvYlVf1jheVzgD/jjEkO8C9VfUlEJgJ/8yg6AJipqgtF5DXgQiDHXTZHVTfUNbbo6GhSU1PJyMio66qmEiEhIURHR/s6DNMEHC0oZsX2DL7dtJWypK8YWbqRX/hvJkqyIBBK28Xg32cm9JoAMRdAqw6+DtlU4LXEISL+wLPAJUAqsE5EFqlqxZ9Cv6eqd3nOUNWvgGHudjoAScDnHkUeUNX5nIHAwEB69mzZd7g0pqEczC3gy+9TSN2wnA4HvuE82cwVfntBoKhVO/x7Xwh9LoJeE/C3K58aPW/WOEYDSaqaDCAi84AZQNX30KjctcASVc2v5/iMMV6SV1jC1n0Z7E5cS8H2L+lzdB1X++0gWEooCQgkP2oUZWf/GL8+EwmKGgJ+/r4O2dSBNxNHN2Cfx3QqMKaScteIyHhgB3C/qu6rsHwm8NcK854UkUeA5cBDqlpYcaMicjtwO0CPHvZjH2O8ovAYRw/sJC15Czmp2yk9vIvQY3voVLKfEWQRK85FE4fb9CO/z08IGjyZgB7n0iaolY8DN2fC153jHwPvqmqhiNwBvA5cVL5QRLoAgwHPEY9+CxwAgoAXgAeBUwaVUNUX3OXExsbaJT/GnK7j2ZCVDEd2k39gJ7n7d1CWuYvWx/bStjSLcJxOSIAjtCEzOJrcDmMo7NSbiJ5DaDNgIhF248BmxZuJIw3wvJF9ND90ggOgqpkeky8BFUcxuh74UFWLPdZJd58WisirwK/rLWJjWori45CX4T4Ow7FDPzzPO4TmZVCSewjN3U9Q0Q+jTbYCcrQD+7QThwOHU9KxJ8Gd+9CpxwBi+p5Dh46RtPfdUZkG4s3EsQ7oKyI9cRLGTOBGzwIi0sUjEUwHtlbYxiycGsYp64hzDe2VwGZvBG9Mk1ZcALv/C6lxkHfo1ORQdOqNLgEK/VqRLe04UBrGwdJwMnQke+jM8bCzaBXVl85nDWBAj84M6tKWtq3sktiWymuJQ1VLROQunGYmf+AVVU0UkceAOFVdBNwjItOBEiALmFO+vojE4NRY/lth02+LSCQgwAbA7sRnDEB+Fuz83BnBLmk5FOeB+EGrCGgdCWGRFLcZQaa2Ja24NbuOt2JbbgibjgSSXhJOJm0oCwilf+dwBnZpw8CubTi7SxtmdG1DWLCvW7VNY9Jib3JoTLNwZA9sX+wkiz2rnTvAhkWh/aeR0W0SGwOGsOVQIVvSc9iSnsu+rOMnVu3YOoiBXdswsIuTIAZ2bUOviNYE+NtoC8ZhNzk0pjlQhfSNbrJYDAedIY+Pte3Ljh6zWek3mi9zurHzu3yOF5cC3yMCPSNaMyS6HTNH9TiRLDqFB9tdE8xpscRhTGNXWoymfEPepkUE7FxCSH46ZfixNfBsPi37EZ8Wj2DPwSg4CJ3bBNOvczCzekbQr3MY/aLCGRAVTqsge6ub+mOvJmMameOFxSRv20D2jm9olbqKvrnfEqbH8NcgVpYN5vOy6WwIGUOnTt3o1zmc2zuH0a9zOP06hVuHtWkQljiM8aHjRaVs25PKoa2r0H3r6HhkA/2KtzNI8gDIog3rQs9jf9RFSO8J9Oraid91DqdD6yAfR25aMkscxjSQ/KIStqRls3fHRgr3rKVtxnp6F25lqKTiJ0oZQlrgWeyJugTpPprOAy8gMmYQE+12HKaRscRhjJek5xxn2fok8natIfRQAmcdT2SYJBHr1iby/MI41GEwyd2upH3/8+nQdyzdQ9ud9KtZYxojSxzG1LMjeUUsWLyYmO//yU0Sf6I2kRXWi2NRlyF9zqNNn3NpHdGPnn526atpeixxGFNP8gpLWLh0GZHxf+Onsob8gDCODv8FbQdOwq/bSCJC2vo6RGPqhSUOY85QUUkZn65YSciqp5lV9g2FfqFkjriXjhf/EkLb+To8Y+qdJQ5jTlNZmbJs9VpKv/oj00tWUOwXxKEhdxA19UFCbdQ604xZ4jCmjlSVbxM2kr30f7ikcBll4s/+AT8m+vKHiArv7OvwjPE6SxzG1MHGLVtJ/+RJJuYtQQT29bqBmCsfpnvbrr4OzZgGY4nDmFrYmbyL3QufZHzOIgZJGcndryLmqkfo1fEsX4dmTIOzxGFMNdLS9rH9gycZe/gDelHEjqjLibl6Lv069/F1aMb4jCUOYyooLVM2rlvJsTVvMCLrEyZQyNaIS4i+8jHO7n62r8MzxucscRiD0+G9IzmFPSteI2bfQkaQQhEBbGt/IV2ueJhBvYf7OkRjGg2vJg4RmQL8A2cEwJdU9Y8Vls8B/swPY5H/S1Vfcpc5gwk49qrqdHd+T2Ae0BGIB25W1SJvHodpvtKzctnw1XzabH2P0cXr6C+l7A7qT+LAh+k9cTZD2kb6OkRjGh2vJQ4R8QeeBS4BUoF1IrJIVbdUKPqeqt5VySaOq+qwSub/Cfibqs4TkeeBnwDP1Wfspnk7WlDM6tUrKY1/i9HHljFVcsmWduzoeRPRE35Cz5jKXnbGmHLerHGMBpJUNRlAROYBM4CKiaPWxBmu7CLgRnfW68BcLHGYGhSXlrFm83YOrHqHgQc/ZrLsppgAUiIuoHTsHDqPuIx2/jaWhTG14c3E0Q3Y5zGdCoyppNw1IjIe2AHcr6rl64SISBxQAvxRVRfiNE9lq2qJxza7VbZzEbkduB2gR48eZ3ospglSVTbtzSRx5Qd02rWA8bqOICllf6t+7B0yl+7jb6Zv6whfh2lMk+PrzvGPgXdVtVBE7sCpQVzkLjtLVdNEpBfwpYh8D+TUdsOq+gLwAkBsbKzWc9ymEcvOL2L5119TGv8mEwu/ZKjkcNS/Hft73Uy3CbfStdtQX4doTJPmzcSRBicNLRDND53gAKhqpsfkS8BTHsvS3L/JIrICGA4sANqJSIBb6zhlm6ZlUlXit+8hacVb9EtfyDWykxL8Se88nrzzf0z4oGmEW1OUMd5PzFEAACAASURBVPXCm4ljHdDXvQoqDZjJD30TAIhIF1VNdyenA1vd+e2BfLcmEgGMA55SVRWRr4Brca6smg185MVjMI1c1rFCVi1fROD37zC+eBWxUsih0BgODPs9UefPpntYJ1+HaEyz47XEoaolInIXsBTnctxXVDVRRB4D4lR1EXCPiEzH6cfIAua4q58N/J+IlAF+OH0c5Z3qDwLzROQJYD3wsreOwTROZWVKwuZE0le+yuCMT7hCDpAvoRw4azpdJ95Gp5jRIOLrMI1ptkS1+Tf/x8bGalxcnK/DMGcoI/soCV+8S5tt8xhdkoC/KLvDRhAy+ha6jL0Bglr5OkRjmhURiVfV2Irzfd05bky1ysqUhLhV5Kx+heFHPmeyHOWwXwRJ/e8g5uLb6NnJ7hllTEOzxGEapZzsLDYsfpFOSf8htiyJIgJI6nAhBeNupeuIqUT4+fs6RGNaLEscpvFQ5eC2b0ld9m/OPvw5F0ohewJ6svmc39H34lsZ2MZu/2FMY2CJw/heQQ57/vs6fgmv070wiXANZlP7i+k04Q56DR1vHd3GNDKWOIxvqFKaGs/+5c8RmfIxZ1HIVmJY2vNBhk29jbGdrHZhTGNlicM0rIIcChLmkbf6JToe20EHDWZZ4HgYOYeJEydzdoj9SM+Yxs4Sh/E+VUiLJ//bFwnYupCQsgKSymKY3/Zuel00h6lDe+PvZ81RxjQVljiM9+RnweYFHF/zMqFZW1ENZkHZeezteQOXTprMHWd18HWExpjTYInD1B9VyNgOOz6jdNsS/FK/QyhjV1kM8/kpoSNncuMFg+jewX6oZ0xTZonDnJmSQtizCnYspWz7Evyy9wCwTWNYVjqD9aHncd4Fk/jl6B60sf4LY5oFSxym7o5lwM7PYcdn6K7lSFEeRRLEN6Xn8EXpxXwfOobYIecw9Zwo7orpYP0XxjQzljhMzVTh4GbY8RnsWIqmxiEoWf4RLC06l89Lh5PcegQTh5/F1UO68GSP9vhZsjCm2bLEYap2ZA+s+gfsWAq5qQAkBw1gUem1fFEynKzw/kwd3ZW7hkQxvLslC2NaCkscpkqlH9+HpqxiQ3AsC0qmsaxkGEEhXZg6JorHh3RhWHQ7SxbGtECWOEzlCo+iu7/mleJLeSP4p0w7rwsvDu7C0Oi2iN0CxJgWzRKHqVTxzuUEajHFvSfz9ZyJliyMMSf4eXPjIjJFRLaLSJKIPFTJ8jkikiEiG9zHT935w0TkWxFJFJFNInKDxzqvichuj3WGefMYWqrD8R+Ro60YNOYSSxrGmJPUWOMQkSuAT1W1rC4bFhF/4FngEiAVWCciizyGgC33nqreVWFePnCLqu4Uka5AvIgsVdVsd/kDqjq/LvGYOigrJXzvl/yX4Vzcr7OvozHGNDK1qXHcAOwUkadEZEAdtj0aSFLVZFUtAuYBM2qzoqruUNWd7vP9wCHAbpfaQEpT4wkrzeZQl4kEB9iAScaYk9WYOFT1R8BwYBfwmtuEdLuIhNewajdgn8d0qjuvomvc5qj5ItK94kIRGQ0Eufsv96S7zt9EJLimYzB1cyjuQ0rUj6iRl/s6FGNMI1SrPg5VzQXm49QaugBXAQkicvcZ7v9jIEZVhwBfAK97LhSRLsCbwI89msp+CwwARgEdgAcr27Cb3OJEJC4jI+MMw2xZ/HcuJV77c/5gG8/bGHOqGhOHiEwXkQ+BFUAgMFpVpwJDgV9Vs2oa4FmDiHbnnaCqmapa6E6+BIz02G8b4FPg/6nqGo910tVRCLyK0yR2ClV9QVVjVTU2MtJauWpLj+yh0/FdJHe4gHC7t5QxphK1uRz3GuBvqrrSc6aq5ovIT6pZbx3QV0R64iSMmcCNngVEpIuqpruT04Gt7vwg4EPgjYqd4OXriHOpz5XA5locg6mlg/EfEQWEDbnC16EYYxqp2iSOuUD5hzsiEgp0VtUUVV1e1UqqWiIidwFLAX/gFVVNFJHHgDhVXQTcIyLTgRIgC5jjrn49MB7oKCLl8+ao6gbgbRGJBATYANxZ24M1NStMXMzusijGjKq0ImeMMYiqVl9AJA44z70yqrw2sEpVRzVAfPUiNjZW4+LifB1G41d4lOL/jWFJq+lM/82rvo7GGONjIhKvqrEV59emczygPGkAuM+D6jM40zgc3rSUQEqQ/lN8HYoxphGrTeLIcJuTABCRGcBh74VkfCUrYRE52orBYyf7OhRjTCNWmz6OO3H6Ff6F06+wD7jFq1GZhldWRqeD/yUhKJaJndv5OhpjTCNWY+JQ1V3AWBEJc6ePeT0q0+Bydq2lXVk2x3tf7OtQjDGNXK3ujisilwGDgJDyG96p6mNejMs0sLS1H9Ba/eg59kpfh2KMaeRq8wPA53HuV3U3TlPVdcBZXo7LNLDwvcv43m8AA3r18HUoxphGrjad4+ep6i3AEVX9A3Au0M+7YZmGlH8ohe5FyWR0vchuoW6MqVFtEkeB+zffvcV5Mc79qkwzsXv1AgAiR1ozlTGmZrXp4/hYRNoBfwYSAAVe9GpUpkH57fyMPXRh8NCRNRc2xrR41SYOEfEDlrsDKC0QkU+AEFXNaZDojNcVH8+ld14C33a8mrP8vTogpDGmmaj2k8K9lfmzHtOFljSal53ffkIQJbQebGNvGGNqpzZfMZeLyDVivabN0vHNn5KrrTjHfi1ujKml2iSOO4D3gUIRyRWRoyKS6+W4TAMoKy0lJusbtoePISQkxNfhGGOaiNr8crymIWJNE7Vzw0r6k01yP7upoTGm9mpMHCIyvrL5FQd2Mk1PZsJHlKgf/cdd7etQjDFNSG0ux33A43kIzlCt8cBFXonINJhO6SvYGTyIszt28nUoxpgmpDZNVSeNISoi3YG/ey0i0yBSdm2nT9lu4mPu93Uoxpgm5nQu3E8Fzq5NQRGZIiLbRSRJRB6qZPkcEckQkQ3u46cey2aLyE73Mdtj/kgR+d7d5jN2tdfpSVnzAQA9zr3Gx5EYY5qa2vRx/BPn1+LgJJphOL8gr2k9f5zfgFyCk2zWicgiVd1Soeh7qnpXhXU7AI8Cse6+4911jwDPAbcBa4HFwBRgSU3xmJOFpSxjv39Xusac4+tQjDFNTG36ODwH6y4B3lXVVbVYbzSQpKrJACIyD5gBVEwclZkMfKGqWe66XwBTRGQF0EZV17jz3wCuxBJHnRw4fJjBRRvZGn0dXa3CZoypo9okjvlAgaqWglOTEJFWqppfw3rdcEYLLJcKjKmk3DXulVs7gPtVdV8V63ZzH6mVzD+FiNwO3A7Qo4fdKtzT1lUfM1GKiRw5w9ehGGOaoFr9chwI9ZgOBZbV0/4/BmJUdQjwBfB6PW0XVX1BVWNVNTYyMrK+Nts8bP+MY7Sm29BJvo7EGNME1SZxhHgOF+s+b1WL9dKA7h7T0e68E1Q1U1UL3cmXgJE1rJvmPq9ym6Z6OXmFnJP3Lfs6ngv+gb4OxxjTBNUmceSJyIjyCREZCRyvxXrrgL4i0lNEgoCZwCLPAiLiOa7HdGCr+3wpcKmItBeR9sClwFJVTQdyRWSsezXVLcBHtYjFuBLWLCdScmh1zmW+DsUY00TVpo/jPuB9EdmPM3RsFM5QstVS1RIRuQsnCfgDr6hqoog8BsSp6iLgHhGZjtPpngXMcdfNEpHHcZIPwGPlHeXAz4HXcJrMlmAd43WSv3kxpfjRfZT1bxhjTo+oas2FRAKB/u7kdlUt9mpU9Sw2Nlbj4uJqLtjMFRSXkvzECFqFtSXmAbtjjDGmeiISr6qxFefX2FQlIr8AWqvqZlXdDISJyM+9EaTxrrUbNjFQUtC+dgt1Y8zpq00fx23uCIAAuD/Cu817IRlvOZzwMQDRY+2mhsaY01ebxOHveVsP9xfhQd4LyXhDSWkZndK/JCOwG4GdB/g6HGNME1abxPEZ8J6ITBKRScC7WId0kxO/M43Rupm8syaB/VrcGHMGanNV1YM4v8C+053ehHNllWlCkr/7hDFSTNSoK30dijGmiauxxqGqZTg3FEzBuf/URfzwewvTBKgqrfcsI19aE9L7Al+HY4xp4qqscYhIP2CW+zgMvAegqhMbJjRTXxLTshlbEsfhrufTI8C6p4wxZ6a6Gsc2nNrF5ap6vqr+EyhtmLBMfdqwdgWdJJsOw6f7OhRjTDNQXeK4GkgHvhKRF92OcetVbYJ0x2eU4UfYOdN8HYoxphmoMnGo6kJVnQkMAL7CufVIJxF5TkQubagAzZnZfTiP4cfXcKjdUGjVwdfhGGOagdp0juep6jvu2OPRwHqcK61ME7AqfiPn+KUQOshqG8aY+lGnMcdV9Yg7zoUN5NBE5G3+FIC2Q61/wxhTP+qUOEzTcuhoAX2yV5ET0g0i+9e8gjHG1IIljmbsy+9TGOe3mdK+U+zX4saYemOJo5nKPFbI+hULCZFi2g+7wtfhGGOaEUsczVBRSRk/fyuOyQVLKQ0MQ84a5+uQjDHNiFcTh4hMEZHtIpIkIg9VU+4aEVERiXWnbxKRDR6PMhEZ5i5b4W6zfFknbx5DU6OqPLookfGpz3ORXwL+Ex4E+7W4MaYe1eYmh6fFvf36s8AlQCqwTkQWqeqWCuXCgXtx7ocFgKq+DbztLh8MLFTVDR6r3aSqNqRfJd74dg9l8a/zi8BFMHIOnHe3r0MyxjQz3qxxjAaSVDVZVYuAeUBlA10/DvwJKKhiO7PcdU0Nvtl5mOWfzuN/Al9Ge0+CaX+xTnFjTL3zZuLoBuzzmE51550gIiOA7qr6aTXbuQFnDBBPr7rNVA97DjJVYdu3i0iciMRlZGScRvhNy+7Defz17Q95LvAfEDkAue418PdahdIY04L5rHNcRPyAvwK/qqbMGCDfHeu83E2qOhi4wH3cXNm67g8VY1U1NjIysh4jb3xyC4r5zatLeZb/Jbh1G/x/9D6EtPF1WMaYZsqbiSMN6O4xHe3OKxcOnAOsEJEUYCywqLyD3DWTCrUNVU1z/x4F3sFpEmuxSsuUX721mkeOPkangOME/Og/0Dba12EZY5oxbyaOdUBfEekpIkE4SWBR+UJVzVHVCFWNUdUYYA0wvbzT262RXI9H/4aIBIhIhPs8ELgc8KyNtDh/WryZ6/fMZZDfHvyvfw26DPV1SMaYZs5rjeCqWiIidwFLAX/gFVVNFJHHgDhVXVT9FhgP7FPVZI95wcBSN2n4A8uAF70QfpPwftw+uqx5nEsCEmDa09Bvsq9DMsa0AF7tPVXVxcDiCvMeqaLshArTK3Carzzn5QEj6zXIJip+TxbbPvozDwcspXTMz/EffZuvQzLGtBB22U0TlJZ9nLdff56n/d+gqO9lBE1+wtchGWNaEEscTUx+UQl/enkefyz9O0WdhxBy3Uvg5+/rsIwxLYjdq6oJKStT/uedpfw+dy7SOoKQW+ZDUCtfh2WMaWGsxtGEPP/5em5O/g1tg0oInvMBhNltuowxDc8SRxOxeMNeBq+6mz7+6fjd+AF0GuDrkIwxLZQ1VTUBm1Ozyf/gbi7w30zZFc8gvSb4OCJjTEtmiaORyzhayDev/pZr/VaQN/aXBI78ka9DMsa0cJY4GrHCklLefPFp7ix9h+w+V9F6cqU/gTHGmAZlfRwNTFU5WlhC1rEiMvOKyMorIiuv0Hl+rIjsY/lobhpBx/bT9tgu7i99lczIWDrO/D+7RboxplGwxOFFK7Yf4sP1aWSeSBKFFOXlEFmWQTc5fNJjtGQSLYfpJEfwQ09sI7dNbzre+j4EBPvwSIwx5geWOLxEVZm/8APGHf+S3kHZdNEMOpYeolXgsZPKlfkFUhbWFWnXHf/2sc6dbdt1d/627UGb9meBf6CPjsIYY05licNLdhw8xi/ynqVvwCEC2veBtv2g7SSPxOA8/MI64+dnXU3GmKbDEoeXfLtuDXP89nL0wscJv/AeX4djjDH1xr7qeokmOneNDx92jY8jMcaY+mWJwwuSM44Rm7+Sg22HQNtuNa9gjDFNiCUOL1i1Lo7BfimEDL3a16EYY0y9s8ThBSWbFwLQdoQ1Uxljmh+vJg4RmSIi20UkSUQeqqbcNSKiIhLrTseIyHER2eA+nvcoO1JEvne3+YxI4/pV3L6sfIYf+y+HwgdBux6+DscYY+qd1xKHiPgDzwJTgYHALBEZWEm5cOBeYG2FRbtUdZj7uNNj/nPAbUBf9zHFG/Gfrm/WJTDML5nAIdZMZYxpnrxZ4xgNJKlqsqoWAfOAGZWUexz4E1BQ0wZFpAvQRlXXqKoCbwBX1mPMZ6zw+w8BaD/SmqmMMc2TNxNHN2Cfx3SqO+8EERkBdFfVTytZv6eIrBeR/4rIBR7bTK1umx7bvl1E4kQkLiMj47QPoi4O5BQwJHcFh8IGQIeeDbJPY4xpaD7rHBcRP+CvwK8qWZwO9FDV4cAvgXdEpE1dtq+qL6hqrKrGRkZGnnnAtfB1/AZG+CXhP6hRVYKMMaZeefOX42lAd4/paHdeuXDgHGCF278dBSwSkemqGgcUAqhqvIjsAvq560dXs02fytvgNFN1HH29jyMxxhjv8WaNYx3QV0R6ikgQMBNYVL5QVXNUNUJVY1Q1BlgDTFfVOBGJdDvXEZFeOJ3gyaqaDuSKyFj3aqpbgI+8eAy1dvhYIedkf8mhVn2hY29fh2OMMV7jtcShqiXAXcBSYCvwH1VNFJHHRGR6DauPBzaJyAZgPnCnqma5y34OvAQkAbuAJV45gDr6On4TsX47YGBl/f/GGNN8ePUmh6q6GFhcYV6lw9ip6gSP5wuABVWUi8Np4mpUctc7zVSRY6yZyhjTvNkvx+tBdn4RA7K+JCO0FxLZ39fhGGOMV1niqAcrExIZJdsoHWDNVMaY5s8SRz3ISfgAP1E6j7VmKmNM82eJ4wwdLSimz+HlHA45C+l0tq/DMcYYr7PEcYa+2biN0bKFon5XQOO636IxxniFJY4zlBn3Af6iRJ0709ehGGNMg7DEcQbyi0roeegLDgd3xy+q0V0hbIwxXmGJ4wys3rSDMSRS0Pdya6YyxrQYljjOwMG4DwmQMqLG3uDrUIwxpsFY4jhNBcWl9Ej/nMygrgR0G+brcIwxpsFY4jhNaxJ3MZbvyettzVTGmJbFEsdpSv/uAwKllC7nWjOVMaZlscRxGopKyui6fylZgVEEdh/p63CMMaZBWeI4Dd9tS2GsbiK35zRrpjLGtDiWOE5D2toFBEsJXc6zZipjTMtjiaOOSkrL6LxvKUcCIgnuMdrX4RhjTIPzauIQkSkisl1EkkTkoWrKXSMiKiKx7vQlIhIvIt+7fy/yKLvC3eYG99HJm8dQUdzOvZyrG8iOmQp+lneNMS2P10YAdMcMfxa4BEgF1onIIlXdUqFcOHAvsNZj9mHgClXdLyLn4Aw/281j+U3uSIANbu+ahYyVYrrYvamMMS2UN78yjwaSVDVZVYuAeUBlIx09DvwJKCifoarrVXW/O5kIhIpIsBdjrZWyMiViz2Ky/TsS0vNcX4djjDE+4c3E0Q3Y5zGdysm1BkRkBNBdVT+tZjvXAAmqWugx71W3mephkcovaxKR20UkTkTiMjIyTvMQTrYxOZXzyhLI6jHZmqmMMS2Wzz79RMQP+Cvwq2rKDMKpjdzhMfsmVR0MXOA+bq5sXVV9QVVjVTU2MjKyXmLetXohIVJMlP3ozxjTgnkzcaQB3T2mo9155cKBc4AVIpICjAUWeXSQRwMfAreo6q7ylVQ1zf17FHgHp0nM61SV9ilLyPFrT6s+FzTELo0xplHyZuJYB/QVkZ4iEgTMBBaVL1TVHFWNUNUYVY0B1gDTVTVORNoBnwIPqeqq8nVEJEBEItzngcDlwGYvHsMJm/cc4NzSODK6Xwp+/g2xS2OMaZS8ljhUtQS4C+eKqK3Af1Q1UUQeE5HpNax+F9AHeKTCZbfBwFIR2QRswKnBvOitY/CUtHohraTQbqFujGnxvHY5LoCqLgYWV5j3SBVlJ3g8fwJ4oorNNvjNoVSV8F2fkuvXljb9Lmzo3RtjTKNilwbVwvbUDMaWrONgt0vA36u51hhjGj1LHLWwfdVHhEkBkaOv93Uoxhjjc5Y4aqH1rk84KuG0G3hRzYWNMaaZs8RRg6T0TEYXrSW9yyTwD/R1OMYY43OWOGqw9ZtFtJHjRIyxq6mMMQYscdQodOfHHJMwOgy62NehGGNMo2CJoxp7D2UzqvBb9neeCAFBvg7HGGMaBUsc1dj8zSLaSj7tR13n61CMMabRsMRRjeCdn5AnrYgcOsXXoRhjTKNhv2arxvljxpCf05fWAT4fCsQYYxoNSxzVCJ7wKyxlGGPMyaypyhhjTJ1Y4jDGGFMnljiMMcbUiSUOY4wxdWKJwxhjTJ1Y4jDGGFMnljiMMcbUiSUOY4wxdSKq6usYvE5EMoA9p7l6BHC4HsOpbxbfmbH4zozFd2Yae3xnqWpkxZktInGcCRGJU9VYX8dRFYvvzFh8Z8biOzONPb6qWFOVMcaYOrHEYYwxpk4scdTsBV8HUAOL78xYfGfG4jszjT2+SlkfhzHGmDqxGocxxpg6scRhjDGmTixxuERkiohsF5EkEXmokuXBIvKeu3ytiMQ0YGzdReQrEdkiIokicm8lZSaISI6IbHAfjzRUfO7+U0Tke3ffcZUsFxF5xj1/m0RkRAPG1t/jvGwQkVwRua9CmQY9fyLyiogcEpHNHvM6iMgXIrLT/du+inVnu2V2isjsBozvzyKyzf3/fSgi7apYt9rXghfjmysiaR7/w2lVrFvte92L8b3nEVuKiGyoYl2vn78zpqot/gH4A7uAXkAQsBEYWKHMz4Hn3eczgfcaML4uwAj3eTiwo5L4JgCf+PAcpgAR1SyfBiwBBBgLrPXh//oAzg+bfHb+gPHACGCzx7yngIfc5w8Bf6pkvQ5Asvu3vfu8fQPFdykQ4D7/U2Xx1ea14MX45gK/rsX/v9r3urfiq7D8L8Ajvjp/Z/qwGodjNJCkqsmqWgTMA2ZUKDMDeN19Ph+YJCLSEMGparqqJrjPjwJbgW4Nse96NAN4Qx1rgHYi0sUHcUwCdqnq6d5JoF6o6kogq8Jsz9fY68CVlaw6GfhCVbNU9QjwBTClIeJT1c9VtcSdXANE1/d+a6uK81cbtXmvn7Hq4nM/N64H3q3v/TYUSxyObsA+j+lUTv1gPlHGffPkAB0bJDoPbhPZcGBtJYvPFZGNIrJERAY1aGCgwOciEi8it1eyvDbnuCHMpOo3rC/PH0BnVU13nx8AOldSprGcx1txapCVqem14E13uU1pr1TR1NcYzt8FwEFV3VnFcl+ev1qxxNGEiEgYsAC4T1VzKyxOwGl+GQr8E1jYwOGdr6ojgKnAL0RkfAPvv0YiEgRMB96vZLGvz99J1GmzaJTXyovI/wNKgLerKOKr18JzQG9gGJCO0xzUGM2i+tpGo38vWeJwpAHdPaaj3XmVlhGRAKAtkNkg0Tn7DMRJGm+r6gcVl6tqrqoec58vBgJFJKKh4lPVNPfvIeBDnCYBT7U5x942FUhQ1YMVF/j6/LkOljffuX8PVVLGp+dRROYAlwM3ucntFLV4LXiFqh5U1VJVLQNerGK/vj5/AcDVwHtVlfHV+asLSxyOdUBfEenpfiudCSyqUGYRUH4Fy7XAl1W9ceqb2yb6MrBVVf9aRZmo8j4XERmN879tkMQmIq1FJLz8OU4n6uYKxRYBt7hXV40FcjyaZRpKld/0fHn+PHi+xmYDH1VSZilwqYi0d5tiLnXneZ2ITAF+A0xX1fwqytTmteCt+Dz7zK6qYr+1ea9708XANlVNrWyhL89fnfi6d76xPHCu+tmBc8XF/3PnPYbzJgEIwWniSAK+A3o1YGzn4zRbbAI2uI9pwJ3AnW6Zu4BEnKtE1gDnNWB8vdz9bnRjKD9/nvEJ8Kx7fr8HYhv4/9saJxG09Zjns/OHk8DSgWKcdvaf4PSZLQd2AsuADm7ZWOAlj3VvdV+HScCPGzC+JJz+gfLXYPlVhl2BxdW9Fhoovjfd19YmnGTQpWJ87vQp7/WGiM+d/1r5a86jbIOfvzN92C1HjDHG1Ik1VRljjKkTSxzGGGPqxBKHMcaYOrHEYf5/e3fzWkcVh3H8+9gWrLgQMQoKWhChugq2RboQqRVciNhFFEtFq1QQxKVgpRQ3vuNK8aUKRkpcuRDUZWNU4ktLtW/4B+hCoQUFAxVLfFz8zpXbcG/ilJpY7/OBgXNnzpkZEpLDzNx5fhERnWTiiIiITjJxxMiS9LykLZK2SdrdceyYKiX5O0m3Ltj2jqSbWvvp83zOOyVdPehYEcslX8eNkSVpGrgLeA74wPZsh7H3A3fY3rVEvznbl3Y8r1W254dsm6ESYP+bcdsxEnLFESOn1ZU4BmwCvgJ2AW9oQA0OSeskTbfgvAOSrpU0TkWg39NqJqxdMGZG0kZJLwBrW5+ptu0BSQfburckrWrr5yS9IukoFba4V9IhSSck7Wtv3E9QLwNO9Y7bO1bbx3ZVHYcTkl7sO585Sc+2AMevJV3V1t/b+h6V9Pn5/0nH/9ZKv4GYJctKLNSk8SqwBphdpN9HwEOt/QjwYWvvBF4bMmaG9mY8MNe3/sa2vzXt8+vAg61t4L6+vpf3tfcDdy/cd/9n6u3jH4AxYDUwDWzr23dv/EvAntY+DlzT2pet9O8ky4Wz5IojRtXNVKzDeqq+yTCbgfdbez8V/3KutgIbgEOq6m9bqYgJgHkqxLJnS3uGchy4HVgq5n0TMGP7pCv2f4oqJgTwB/Bxax8G1rX2LDAp6VGqwFHEP7J6pU8gYjm120yTVCrqKeCSWq0jwGbbp//NwwPv2R70IP53t+caki6mrkY22v5R0jNUVtq5OmO79zBznvZ3b/sxSbdQz3kOS9pge7mDHeMClCuOGCm2j9gep5XfpW7p3Gl7fMik8SWVoAqwA/ii4yHPtEh8qADDp5GICgAAANJJREFUCUlXwt81xq8bMKY3SZxS1WCZ6Nv2G1U+eKGDwG2SrmjPTbYDny12YpKut/2N7b3ASc6OG48YKlccMXIkjQG/2P5T0nrb3y/S/QngXUlPUv9cH+54uH3AMUnf2t4haQ9V3e0iKjn1ceCsMra2f5X0NhWn/TMVBd4zCbwp6TR1G6035idJTwGfUlc2n9geFMve72VJN7T+B6hbdxFLytdxIyKik9yqioiITjJxREREJ5k4IiKik0wcERHRSSaOiIjoJBNHRER0kokjIiI6+Qv6M0mbK5t6LAAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"h9xTwIf51prF"},"source":["### Part (d) [5 pt]\n","\n","Tune your hyperparameters, training at least 4 different models (4 sets of hyperparameters).\n","\n","Do not include all your training curves. Instead, explain what hyperparameters\n","you tried, what their effect was, and what your thought process was as you \n","chose the next set of hyperparameters to try."]},{"cell_type":"code","metadata":{"id":"PhTKt9iL1prG","executionInfo":{"status":"ok","timestamp":1604550309535,"user_tz":300,"elapsed":173166,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"5647f07f-48cf-4cdd-e896-2f0f9365c7c8","colab":{"base_uri":"https://localhost:8080/"}},"source":["'''\n","1st hyperparameters setting:\n","learning_rate: increasing learning rate to 0.0005 causes the final accuracy increase\n","epochs: same as initial setting\n","batch_size: same as initial setting\n","hidden units: same as initial setting\n","'''\n","\n","# Hyperparameters setting\n","learning_rate=0.0005\n","epochs=20\n","batch_size=64\n","\n","autoencoder = AutoEncoder(hu1=40, hu2=20)\n","_ = train(autoencoder, train_loader, valid_loader, batch_size=batch_size, num_epochs=epochs, learning_rate=learning_rate)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training Started...\n","Epoch 1: Train acc: 53.399, Train loss: 0.0574 | Validation acc: 53.548, Validation loss: 0.05735\n","Epoch 2: Train acc: 58.212, Train loss: 0.0475 | Validation acc: 58.185, Validation loss: 0.04748\n","Epoch 3: Train acc: 59.649, Train loss: 0.04005 | Validation acc: 59.654, Validation loss: 0.04013\n","Epoch 4: Train acc: 60.478, Train loss: 0.0343 | Validation acc: 60.16, Validation loss: 0.03439\n","Epoch 5: Train acc: 60.591, Train loss: 0.02983 | Validation acc: 60.547, Validation loss: 0.02993\n","Epoch 6: Train acc: 60.738, Train loss: 0.02659 | Validation acc: 60.482, Validation loss: 0.0268\n","Epoch 7: Train acc: 61.3, Train loss: 0.02427 | Validation acc: 60.985, Validation loss: 0.02449\n","Epoch 8: Train acc: 61.564, Train loss: 0.02211 | Validation acc: 61.1, Validation loss: 0.02238\n","Epoch 9: Train acc: 61.876, Train loss: 0.02014 | Validation acc: 61.372, Validation loss: 0.02039\n","Epoch 10: Train acc: 61.666, Train loss: 0.01868 | Validation acc: 61.357, Validation loss: 0.01889\n","Epoch 11: Train acc: 61.814, Train loss: 0.01772 | Validation acc: 61.697, Validation loss: 0.01792\n","Epoch 12: Train acc: 62.128, Train loss: 0.01707 | Validation acc: 61.921, Validation loss: 0.01728\n","Epoch 13: Train acc: 62.141, Train loss: 0.01654 | Validation acc: 62.059, Validation loss: 0.01673\n","Epoch 14: Train acc: 61.809, Train loss: 0.01608 | Validation acc: 61.491, Validation loss: 0.01627\n","Epoch 15: Train acc: 62.179, Train loss: 0.01565 | Validation acc: 62.008, Validation loss: 0.01585\n","Epoch 16: Train acc: 62.13, Train loss: 0.01522 | Validation acc: 61.932, Validation loss: 0.0154\n","Epoch 17: Train acc: 61.99, Train loss: 0.01486 | Validation acc: 61.99, Validation loss: 0.01504\n","Epoch 18: Train acc: 62.432, Train loss: 0.01449 | Validation acc: 62.381, Validation loss: 0.01468\n","Epoch 19: Train acc: 62.331, Train loss: 0.0142 | Validation acc: 62.254, Validation loss: 0.0144\n","Epoch 20: Train acc: 62.441, Train loss: 0.01392 | Validation acc: 62.218, Validation loss: 0.01412\n","===============Final training result summary===============\n","Training accuracy:  62.441\n","Training loss:  0.01392\n","Validation accuracy:  62.218\n","Validation loss:  0.01412\n","Total time elapsed: 172.48 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lFHuSNyQtQU8","executionInfo":{"status":"ok","timestamp":1604552339826,"user_tz":300,"elapsed":170886,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"06406faf-f8df-4176-b140-8f106b3c8ffb","colab":{"base_uri":"https://localhost:8080/"}},"source":["'''\n","2nd hyperparameters setting:\n","learning_rate: choosing lr that is bigger or smaller than 0.002555 will not increase the final accuracy, so 0.002555 is the optimal value\n","epochs: same as initial setting\n","batch_size: same as initial setting\n","hidden units: same as initial setting\n","'''\n","# Hyperparameters setting\n","learning_rate=0.002555\n","epochs=20\n","batch_size=64\n","\n","autoencoder = AutoEncoder(hu1=40, hu2=20)\n","_ = train(autoencoder, train_loader, valid_loader, batch_size=batch_size, num_epochs=epochs, learning_rate=learning_rate)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training Started...\n","Epoch 1: Train acc: 58.394, Train loss: 0.03964 | Validation acc: 58.666, Validation loss: 0.03979\n","Epoch 2: Train acc: 59.986, Train loss: 0.02652 | Validation acc: 59.86, Validation loss: 0.02674\n","Epoch 3: Train acc: 60.6, Train loss: 0.02234 | Validation acc: 60.333, Validation loss: 0.02254\n","Epoch 4: Train acc: 60.987, Train loss: 0.01973 | Validation acc: 60.742, Validation loss: 0.01994\n","Epoch 5: Train acc: 62.645, Train loss: 0.01779 | Validation acc: 62.236, Validation loss: 0.01801\n","Epoch 6: Train acc: 63.186, Train loss: 0.01695 | Validation acc: 62.786, Validation loss: 0.01723\n","Epoch 7: Train acc: 63.189, Train loss: 0.01614 | Validation acc: 62.71, Validation loss: 0.01643\n","Epoch 8: Train acc: 63.16, Train loss: 0.01546 | Validation acc: 62.457, Validation loss: 0.01576\n","Epoch 9: Train acc: 64.103, Train loss: 0.01472 | Validation acc: 63.712, Validation loss: 0.015\n","Epoch 10: Train acc: 63.82, Train loss: 0.01413 | Validation acc: 63.354, Validation loss: 0.0144\n","Epoch 11: Train acc: 63.821, Train loss: 0.01375 | Validation acc: 63.346, Validation loss: 0.01407\n","Epoch 12: Train acc: 63.507, Train loss: 0.01441 | Validation acc: 63.288, Validation loss: 0.01464\n","Epoch 13: Train acc: 64.571, Train loss: 0.01308 | Validation acc: 64.084, Validation loss: 0.01341\n","Epoch 14: Train acc: 63.433, Train loss: 0.01327 | Validation acc: 62.793, Validation loss: 0.01357\n","Epoch 15: Train acc: 64.819, Train loss: 0.0127 | Validation acc: 64.377, Validation loss: 0.01296\n","Epoch 16: Train acc: 64.581, Train loss: 0.01258 | Validation acc: 63.979, Validation loss: 0.01281\n","Epoch 17: Train acc: 64.651, Train loss: 0.01234 | Validation acc: 64.185, Validation loss: 0.01259\n","Epoch 18: Train acc: 65.731, Train loss: 0.01197 | Validation acc: 65.126, Validation loss: 0.01223\n","Epoch 19: Train acc: 65.405, Train loss: 0.01172 | Validation acc: 65.068, Validation loss: 0.01196\n","Epoch 20: Train acc: 65.978, Train loss: 0.0116 | Validation acc: 65.679, Validation loss: 0.01182\n","===============Final training result summary===============\n","Training accuracy:  65.978\n","Training loss:  0.0116\n","Validation accuracy:  65.679\n","Validation loss:  0.01182\n","Total time elapsed: 170.41 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HlVJfutw9-B_","executionInfo":{"status":"ok","timestamp":1604555741682,"user_tz":300,"elapsed":87761,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"a47011b5-1727-46b6-c8c8-6f4767ed1d65","colab":{"base_uri":"https://localhost:8080/"}},"source":["'''\n","3rd hyperparameters setting:\n","learning_rate: choosing lr that is bigger or smaller than 0.002555 will not increase the final accuracy, so 0.002555 is the optimal value\n","epochs: decreasing number of epochs causes the final accuracy to decrease. Should increase the value in next setting.\n","batch_size: same as initial setting\n","hidden units: same as initial setting\n","'''\n","# Hyperparameters setting\n","learning_rate=0.002555\n","epochs=10\n","batch_size=64\n","\n","autoencoder = AutoEncoder(hu1=40, hu2=20)\n","_ = train(autoencoder, train_loader, valid_loader, batch_size=batch_size, num_epochs=epochs, learning_rate=learning_rate)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training Started...\n","Epoch 1: Train acc: 60.167, Train loss: 0.03581 | Validation acc: 60.218, Validation loss: 0.03607\n","Epoch 2: Train acc: 61.415, Train loss: 0.02511 | Validation acc: 61.408, Validation loss: 0.02536\n","Epoch 3: Train acc: 61.137, Train loss: 0.02124 | Validation acc: 60.811, Validation loss: 0.0215\n","Epoch 4: Train acc: 61.118, Train loss: 0.01945 | Validation acc: 60.974, Validation loss: 0.01956\n","Epoch 5: Train acc: 61.728, Train loss: 0.01802 | Validation acc: 61.632, Validation loss: 0.01804\n","Epoch 6: Train acc: 62.191, Train loss: 0.01653 | Validation acc: 61.813, Validation loss: 0.01657\n","Epoch 7: Train acc: 62.532, Train loss: 0.01606 | Validation acc: 62.489, Validation loss: 0.01604\n","Epoch 8: Train acc: 62.489, Train loss: 0.01538 | Validation acc: 62.305, Validation loss: 0.01537\n","Epoch 9: Train acc: 63.83, Train loss: 0.01462 | Validation acc: 63.379, Validation loss: 0.01465\n","Epoch 10: Train acc: 63.014, Train loss: 0.01461 | Validation acc: 62.464, Validation loss: 0.01463\n","===============Final training result summary===============\n","Training accuracy:  63.014\n","Training loss:  0.01461\n","Validation accuracy:  62.464\n","Validation loss:  0.01463\n","Total time elapsed: 87.56 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QHnxlIPjx-ZF","executionInfo":{"status":"ok","timestamp":1604555536418,"user_tz":300,"elapsed":344422,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"5292c25c-a06c-4269-a949-70d964d5afaf","colab":{"base_uri":"https://localhost:8080/"}},"source":["'''\n","4th hyperparameters setting:\n","learning_rate: choosing lr that is bigger or smaller than 0.002555 will not increase the final accuracy, so 0.002555 is the optimal value\n","epochs: increasing the number of epochs to 40 increases the final accuracy. Choosing a value that is bigger or smaller than 40 will not increase final accuracy, so 40 is selected as optimal value\n","batch_size: the initial value is 64. I found that decreasing or increasing the value will not increase the final accuracy. So 64 is selected as optimal value\n","hidden units: the previous value was 60. Increasing it to 75 increases the final accuracy. Choosing a value that is bigger or smaller than 75 will not increase final accuracy. So 75 is selected as optimal. \n","'''\n","\n","# Hyperparameters setting\n","learning_rate=0.0025\n","epochs=40\n","batch_size=25\n","\n","autoencoder = AutoEncoder(hu1=45, hu2=30)\n","_ = train(autoencoder, train_loader, valid_loader, batch_size=batch_size, num_epochs=epochs, learning_rate=learning_rate)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training Started...\n","Epoch 1: Train acc: 60.204, Train loss: 0.03533 | Validation acc: 60.348, Validation loss: 0.03553\n","Epoch 2: Train acc: 61.153, Train loss: 0.02321 | Validation acc: 60.804, Validation loss: 0.02353\n","Epoch 3: Train acc: 61.418, Train loss: 0.0187 | Validation acc: 61.017, Validation loss: 0.01897\n","Epoch 4: Train acc: 62.082, Train loss: 0.01657 | Validation acc: 61.849, Validation loss: 0.01675\n","Epoch 5: Train acc: 62.328, Train loss: 0.01533 | Validation acc: 62.073, Validation loss: 0.01546\n","Epoch 6: Train acc: 62.958, Train loss: 0.01439 | Validation acc: 62.565, Validation loss: 0.01455\n","Epoch 7: Train acc: 62.907, Train loss: 0.01341 | Validation acc: 62.453, Validation loss: 0.01348\n","Epoch 8: Train acc: 63.967, Train loss: 0.01302 | Validation acc: 63.628, Validation loss: 0.01309\n","Epoch 9: Train acc: 63.208, Train loss: 0.013 | Validation acc: 63.064, Validation loss: 0.01309\n","Epoch 10: Train acc: 64.775, Train loss: 0.012 | Validation acc: 64.558, Validation loss: 0.0121\n","Epoch 11: Train acc: 64.524, Train loss: 0.01192 | Validation acc: 64.24, Validation loss: 0.012\n","Epoch 12: Train acc: 64.561, Train loss: 0.01151 | Validation acc: 64.229, Validation loss: 0.01159\n","Epoch 13: Train acc: 63.824, Train loss: 0.01122 | Validation acc: 63.686, Validation loss: 0.01136\n","Epoch 14: Train acc: 64.74, Train loss: 0.01091 | Validation acc: 64.261, Validation loss: 0.01106\n","Epoch 15: Train acc: 65.373, Train loss: 0.01046 | Validation acc: 64.996, Validation loss: 0.01063\n","Epoch 16: Train acc: 64.937, Train loss: 0.01047 | Validation acc: 64.609, Validation loss: 0.01064\n","Epoch 17: Train acc: 65.957, Train loss: 0.0102 | Validation acc: 65.404, Validation loss: 0.01034\n","Epoch 18: Train acc: 66.512, Train loss: 0.01008 | Validation acc: 66.026, Validation loss: 0.01026\n","Epoch 19: Train acc: 67.07, Train loss: 0.00969 | Validation acc: 66.45, Validation loss: 0.00986\n","Epoch 20: Train acc: 65.363, Train loss: 0.01002 | Validation acc: 65.046, Validation loss: 0.01022\n","Epoch 21: Train acc: 66.211, Train loss: 0.00963 | Validation acc: 65.705, Validation loss: 0.00982\n","Epoch 22: Train acc: 66.588, Train loss: 0.00981 | Validation acc: 66.193, Validation loss: 0.00997\n","Epoch 23: Train acc: 65.585, Train loss: 0.00961 | Validation acc: 65.119, Validation loss: 0.00981\n","Epoch 24: Train acc: 66.881, Train loss: 0.00955 | Validation acc: 66.591, Validation loss: 0.00973\n","Epoch 25: Train acc: 66.594, Train loss: 0.00977 | Validation acc: 65.994, Validation loss: 0.00996\n","Epoch 26: Train acc: 68.819, Train loss: 0.00923 | Validation acc: 68.302, Validation loss: 0.00937\n","Epoch 27: Train acc: 67.207, Train loss: 0.00938 | Validation acc: 66.804, Validation loss: 0.00956\n","Epoch 28: Train acc: 68.907, Train loss: 0.009 | Validation acc: 68.587, Validation loss: 0.00919\n","Epoch 29: Train acc: 68.367, Train loss: 0.00901 | Validation acc: 67.839, Validation loss: 0.00919\n","Epoch 30: Train acc: 69.352, Train loss: 0.00899 | Validation acc: 68.884, Validation loss: 0.00919\n","Epoch 31: Train acc: 68.375, Train loss: 0.00911 | Validation acc: 67.943, Validation loss: 0.00928\n","Epoch 32: Train acc: 70.264, Train loss: 0.0084 | Validation acc: 69.694, Validation loss: 0.00859\n","Epoch 33: Train acc: 69.369, Train loss: 0.00853 | Validation acc: 68.898, Validation loss: 0.00868\n","Epoch 34: Train acc: 69.811, Train loss: 0.00836 | Validation acc: 69.209, Validation loss: 0.00849\n","Epoch 35: Train acc: 68.226, Train loss: 0.0088 | Validation acc: 67.922, Validation loss: 0.00893\n","Epoch 36: Train acc: 68.639, Train loss: 0.00874 | Validation acc: 68.356, Validation loss: 0.00889\n","Epoch 37: Train acc: 70.206, Train loss: 0.00825 | Validation acc: 69.737, Validation loss: 0.00839\n","Epoch 38: Train acc: 70.809, Train loss: 0.00822 | Validation acc: 70.233, Validation loss: 0.00838\n","Epoch 39: Train acc: 70.836, Train loss: 0.008 | Validation acc: 70.396, Validation loss: 0.00813\n","Epoch 40: Train acc: 71.182, Train loss: 0.00792 | Validation acc: 70.631, Validation loss: 0.00809\n","===============Final training result summary===============\n","Training accuracy:  71.182\n","Training loss:  0.00792\n","Validation accuracy:  70.631\n","Validation loss:  0.00809\n","Total time elapsed: 344.21 seconds\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ymCsZH291prI"},"source":["## Part 4. Testing [12 pt]\n","\n","### Part (a) [2 pt]\n","\n","Compute and report the test accuracy."]},{"cell_type":"code","metadata":{"id":"0OkSbup91prJ","executionInfo":{"status":"ok","timestamp":1604556375528,"user_tz":300,"elapsed":2336,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"886276ef-8469-413f-8108-54af9f70eb50","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Final hyperparameters setting\n","learning_rate=0.0025\n","epochs=40\n","batch_size=25\n","hu1=45\n","hu2=30\n","\n","# loader the chossen setting\n","autoencoder = AutoEncoder(hu1=hu1, hu2=hu2)\n","path = get_model_name(autoencoder.name, batch_size=batch_size, learn_rate=learning_rate, epoch=epochs-1)\n","state = torch.load(path)\n","autoencoder.load_state_dict(state)\n","\n","# get testing data loader\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=1)\n","# get accuracy\n","acc, _ = get_accuracy(autoencoder, test_loader)\n","print(\"The final testing accuracy:\", round(acc*100, 2), \"%\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The final testing accuracy: 70.84 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UEe9yt6L1prM"},"source":["### Part (b) [4 pt]\n","\n","Based on the test accuracy alone, it is difficult to assess whether our model\n","is actually performing well. We don't know whether a high accuracy is due to\n","the simplicity of the problem, or if a poor accuracy is a result of the inherent\n","difficulty of the problem.\n","\n","It is therefore very important to be able to compare our model to at least one\n","alternative. In particular, we consider a simple **baseline**\n","model that is not very computationally expensive. Our neural network\n","should at least outperform this baseline model. If our network is not much\n","better than the baseline, then it is not doing well.\n","\n","For our data imputation problem, consider the following baseline model:\n","to predict a missing feature, the baseline model will look at the **most common value** of the feature in the training set. \n","\n","For example, if the feature \"marriage\" is missing, then this model's prediction will be the most common value for \"marriage\" in the training set, which happens to be \"Married-civ-spouse\".\n","\n","What would be the test accuracy of this baseline model?\n"]},{"cell_type":"code","metadata":{"id":"p45VHp011prN","executionInfo":{"status":"ok","timestamp":1604556511372,"user_tz":300,"elapsed":418,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"fcfda1a5-e72a-4622-de1c-f1ef63f063da","colab":{"base_uri":"https://localhost:8080/"}},"source":["# get most common value of each feature \n","#sum all records \n","summation = train_data.sum(axis=0)\n","#the max value of the onehot encoding will be the most common value of the feature\n","baseline_model_output = get_features(summation)\n","print(baseline_model_output)\n","\n","# get baseline model accuracy\n","def get_baseline_model_accuracy(model=baseline_model_output, data_loader=test_loader):\n","  total = 0\n","  acc = 0\n","  counter = 0\n","\n","  # check each categorical feature\n","  for feature in catcols:\n","      for item in data_loader: \n","        inp = item.detach().numpy()\n","        # check each record\n","        for i in range(len(inp)):\n","            acc += model[feature] == get_feature(inp[i], feature)\n","            total += 1\n","  return acc / total"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'work': 'Private', 'marriage': 'Married-civ-spouse', 'occupation': 'Prof-specialty', 'edu': 'HS-grad', 'relationship': 'Husband', 'sex': 'Male'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5z7TZmFg6Kuy","executionInfo":{"status":"ok","timestamp":1604556544461,"user_tz":300,"elapsed":2242,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"5cf647fa-c7a3-4fdd-cf16-fefaa25bd07b","colab":{"base_uri":"https://localhost:8080/"}},"source":["bs = 1\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=1)\n","accuracy = get_baseline_model_accuracy(baseline_model_output, test_loader) \n","print(\"The accuracy of the baseline model:\", round(accuracy*100, 2), \"%\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The accuracy of the baseline model: 45.84 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QlHu0wxh1prP"},"source":["### Part (c) [1 pt]\n","\n","How does your test accuracy from part (a) compared to your basline test accuracy in part (b)?"]},{"cell_type":"code","metadata":{"id":"1KQdwE_n1prQ"},"source":["'''\n","The test accuracy of my autoencoder from part (a) is higher than the test accuracy of the baseline model in part (b), and my autoencoder model outperforms this baseline model.\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DfQPgu1Q1prS"},"source":["### Part (d) [1 pt]\n","\n","Look at the first item in your test data. \n","Do you think it is reasonable for a human\n","to be able to guess this person's education level\n","based on their other features? Explain."]},{"cell_type":"code","metadata":{"id":"3qbQ1vvT1prT","executionInfo":{"status":"ok","timestamp":1604558057320,"user_tz":300,"elapsed":229,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"dcd66dc3-f90c-4733-db5f-07173b266669","colab":{"base_uri":"https://localhost:8080/"}},"source":["# get first sample in the testing dataset\n","dataiter = iter(test_loader)\n","sample = dataiter.next()\n","sample = sample[0].numpy()\n","first_sample = get_features(sample)\n","print(first_sample)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'work': 'Private', 'marriage': 'Divorced', 'occupation': 'Transport-moving', 'edu': 'HS-grad', 'relationship': 'Not-in-family', 'sex': 'Male'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"22aAelwvCjsh"},"source":["'''\n","It is reasonable to guess a person's education level based on their occupation. Because each type of occupation has a minimun education level. \n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p_d5uuAY1prZ"},"source":["### Part (e) [2 pt]\n","\n","What is your model's prediction of this person's education\n","level, given their other features?\n"]},{"cell_type":"code","metadata":{"id":"kBY5gKXR1pra","executionInfo":{"status":"ok","timestamp":1604558669113,"user_tz":300,"elapsed":227,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"e5d34644-4dcf-4a3f-f66b-3b0bba82f3ee","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Final hyperparameters setting\n","learning_rate=0.0025\n","epochs=40\n","batch_size=25\n","hu1=45\n","hu2=30\n","\n","# loader the chossen setting\n","autoencoder = AutoEncoder(hu1=hu1, hu2=hu2)\n","path = get_model_name(autoencoder.name, batch_size=batch_size, learn_rate=learning_rate, epoch=epochs-1)\n","state = torch.load(path)\n","autoencoder.load_state_dict(state)\n","\n","# get the first element \n","for item in iter(test_loader):\n","    first_sample = item[0]\n","    break\n","\n","# get the sample as loader\n","first_sample_loader = DataLoader(first_sample.unsqueeze(0))\n","\n","# get output of the given sample\n","for item in iter(first_sample_loader): \n","    output = autoencoder(zero_out_feature(item, 'edu')).detach().numpy()\n","    \n","output = output.squeeze(0)\n","output = get_features(output)\n","print(output['edu'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["HS-grad\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fdLNA0ce1prd"},"source":["### Part (f) [2 pt]\n","\n","What is the baseline model's prediction\n","of this person's education level?"]},{"cell_type":"code","metadata":{"id":"TXgoM9qk1prd","executionInfo":{"status":"ok","timestamp":1604558671207,"user_tz":300,"elapsed":530,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"10486203197176795767"}},"outputId":"bda627d4-8a32-466c-bdbe-42dddaba66e5","colab":{"base_uri":"https://localhost:8080/"}},"source":["output = baseline_model_output['edu']\n","print(output)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["HS-grad\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"69238fKPJWey"},"source":["'''\n","The most common value for education level is also 'HS-grad'\n","'''"],"execution_count":null,"outputs":[]}]}